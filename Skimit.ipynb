{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skimit.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Pfz_b-Tmapdz"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDWUcMGOauy8"
      },
      "source": [
        "# Skimit ðŸ“„\n",
        "\n",
        "We're going to be replicating the deep learning model behind the 2017 paper [*PubMed 200k RCT: a Dataset for Sequenctial Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071).\n",
        "\n",
        "When it was released, the paper presented a new dataset called PubMed 200k RCT which consists of ~200,000 labelled Randomized Controlled Trial (RCT) abstracts.\n",
        "\n",
        "The goal of the dataset was to explore the ability for NLP models to classify sentences which appear in sequential order.\n",
        "\n",
        "In other words, given the abstract of a RCT, what role does each sentence serve in the abstract?\n",
        "\n",
        "![Skimlit example inputs and outputs](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-skimlit-overview-input-and-output.png)\n",
        "\n",
        "*Example inputs ([harder to read abstract from PubMed](https://pubmed.ncbi.nlm.nih.gov/28942748/)) and outputs ([easier to read abstract](https://pubmed.ncbi.nlm.nih.gov/32537182/)) of the model we're going to build. The model will take an abstract wall of text and predict the section label each sentence should have.*  \n",
        "\n",
        "### Model Input\n",
        "\n",
        "For example, can we train an NLP model which takes the following input (note: the following sample has had all numerical symbols replaced with \"@\"):\n",
        "\n",
        "> To investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ). A total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks. Outcome measures included pain reduction and improvement in function scores and systemic inflammation markers. Pain was assessed using the visual analog pain scale ( @-@ mm ).\n",
        "Secondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ).,\n",
        "Serum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured.\n",
        "There was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks. The mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively. Further , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group. These differences remained significant at @ weeks. The Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ). Low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ).\n",
        "\n",
        "### Model output\n",
        "\n",
        "And returns the following output:\n",
        "\n",
        "```\n",
        "['###24293578\\n',\n",
        " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
        " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
        " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
        " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
        " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
        " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
        " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
        " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
        " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
        " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
        " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
        " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
        " '\\n']\n",
        " ```\n",
        "\n",
        "### Problem in a sentence\n",
        "\n",
        "The number of RCT papers released is continuing to increase, those without structured abstracts can be hard to read and in turn slow down researchers moving through the literature. \n",
        "\n",
        "### Solution in a sentence\n",
        "\n",
        "Create an NLP model to classify abstract sentences into the role they play (e.g. objective, methods, results, etc)  to enable researchers to skim through the literature (hence Skimit) and dive deeper when necessary.\n",
        "\n",
        "> ðŸ“– **Resources:** \n",
        "1. Where the data is coming from: [*PubMed 200k RCT: a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/abs/1710.06071)\n",
        "2. Where the model is coming from: [*Neural networks for joint sentence\n",
        "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
        "\n",
        "## Plan\n",
        "\n",
        "* Downloading a text dataset ([PubMed RCT200k from GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct))\n",
        "* Writing a preprocessing function to prepare our data for modelling\n",
        "* Setting up a series of modelling experiments\n",
        "  * Making a baseline (TF-IDF classifier)\n",
        "  * Deep models with different combinations of: token embeddings, character embeddings, pretrained embeddings, positional embeddings\n",
        "* Building a multimodal model (taking multiple types of data inputs)\n",
        "  * Replicating the model architecture from https://arxiv.org/pdf/1612.05251.pdf \n",
        "* Find the most wrong predictions\n",
        "* Making predictions on PubMed abstracts from the wild"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NG3nevdEZBs"
      },
      "source": [
        "## Confirm access to a GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsuQCg5Uaw1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b4cf0b-aebb-487f-b73d-a36f6d11a448"
      },
      "source": [
        "# Check for GPU\n",
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-3b9692bb-0954-5ebe-f9e9-728f67e0a583)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MdzfDdzaQCb"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Before we can start building a model, we've got to download the PubMed 200k RCT dataset.\n",
        "\n",
        "The authors of the paper have made the data they used for their research availably publically and for free in the form of .txt files [on GitHub](https://github.com/Franck-Dernoncourt/pubmed-rct)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0qt0M55a98x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d12010-962c-4905-8d5d-c59b9ad0202f"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3Oe1F6e7y0E"
      },
      "source": [
        "Checking the contents of the downloaded repository, we can see there are four folders.\n",
        "\n",
        "Each contains a different version of the PubMed 200k RCT dataset.\n",
        "\n",
        "Looking at the [README file](https://github.com/Franck-Dernoncourt/pubmed-rct) from the GitHub page, we get the following information:\n",
        "* PubMed 20k is a subset of PubMed 200k. I.e., any abstract present in PubMed 20k is also present in PubMed 200k.\n",
        "* `PubMed_200k_RCT` is the same as `PubMed_200k_RCT_numbers_replaced_with_at_sign`, except that in the latter all numbers had been replaced by `@`. (same for `PubMed_20k_RCT` vs. `PubMed_20k_RCT_numbers_replaced_with_at_sign`).\n",
        "* Since Github file size limit is 100 MiB, we had to compress `PubMed_200k_RCT\\train.7z` and `PubMed_200k_RCT_numbers_replaced_with_at_sign\\train.zip`. To uncompress `train.7z`, you may use 7-Zip on Windows, Keka on Mac OS X, or p7zip on Linux.\n",
        "\n",
        "To begin with, the dataset we're going to be focused on is `PubMed_20k_RCT_numbers_replaced_with_at_sign`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crmxKEJ69bNW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d4f337-17ca-490b-c25c-36405216a981"
      },
      "source": [
        "# Check what files are in the PubMed_20K dataset \n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joApaTyD_DYL"
      },
      "source": [
        "* `train.txt` - training samples.\n",
        "* `dev.txt` - dev is short for development set, which is another name for validation set (in our case, we'll be using and referring to this file as our validation set).\n",
        "* `test.txt` - test samples.\n",
        "\n",
        "To save ourselves typing out the filepath to our target directory each time, let's turn it into a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1Zp21fGbBUJ"
      },
      "source": [
        "# Start by using the 20k dataset\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWqMrjLCbFTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f1fc3c-d9f8-4c1c-fc3b-d9b0827045df"
      },
      "source": [
        "# Check all of the filenames in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTjZ9NziaeKU"
      },
      "source": [
        "## Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yjdhJxbbIhX"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  \"\"\"\n",
        "  Reads filename (a text file) and returns the lines of text as a list.\n",
        "  \n",
        "  Args:\n",
        "      filename: a string containing the target filepath to read.\n",
        "  \n",
        "  Returns:\n",
        "      A list of strings with one string per line from the target filename.\n",
        "      For example:\n",
        "      [\"this is the first line of filename\",\n",
        "       \"this is the second line of filename\",\n",
        "       \"...\"]\n",
        "  \"\"\"\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpeOUfnkCNII"
      },
      "source": [
        "Alright, we've got a little function, `get_lines()` which takes the filepath of a text file, opens it, reads each of the lines and returns them.\n",
        "\n",
        "Let's try it out on the training data (`train.txt`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT7RMQsEbI0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d32079b-fc3b-4a01-8f9f-fd889601ca90"
      },
      "source": [
        "train_lines = get_lines(data_dir+\"train.txt\")\n",
        "train_lines[:15] # the whole first example of an abstract + a little more of the next one"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-IfwKVAbJAy"
      },
      "source": [
        "Reading the lines from the training text file results in a list of strings containing different abstract samples, the sentences in a sample along with the role the sentence plays in the abstract.\n",
        "\n",
        "The role of each sentence is prefixed at the start of each line separated by a tab (`\\t`) and each sentence finishes with a new line (`\\n`).\n",
        "\n",
        "Different abstracts are separated by abstract ID's (lines beginning with `###`) and newlines (`\\n`).\n",
        "\n",
        "Let's write a function to perform the following steps:\n",
        "* Take a target file of abstract samples.\n",
        "* Read the lines in the target file.\n",
        "* For each line in the target file:  \n",
        "  * If the line begins with `###` mark it as an abstract ID and the beginning of a new abstract.\n",
        "    * Keep count of the number of lines in a sample.\n",
        "  * If the line begins with `\\n` mark it as the end of an abstract sample.\n",
        "    * Keep count of the total lines in a sample.\n",
        "  * Record the text before the `\\t` as the label of the line.\n",
        "  * Record the text after the `\\t` as the text of the line.\n",
        "* Return all of the lines in the target text file as a list of dictionaries containing the key/value pairs:\n",
        "  * `\"line_number\"` - the position of the line in the abstract (e.g. `3`).\n",
        "  * `\"target\"` - the role of the line in the abstract (e.g. `OBJECTIVE`).\n",
        "  * `\"text\"` - the text of the line in the abstract.\n",
        "  * `\"total_lines\"` - the total lines in an abstract sample (e.g. `14`).\n",
        "* Abstract ID's and newlines should be omitted from the returned preprocessed data.\n",
        "\n",
        "Example returned preprocessed sample (a single line from an abstract):\n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "  'target': 'OBJECTIVE',\n",
        "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
        "  'total_lines': 11},\n",
        "  ...]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B65Ffn9abJKH"
      },
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence number\n",
        "  the target line is.\n",
        "\n",
        "  Args:\n",
        "      filename: a string of the target text file to read and extract line data\n",
        "      from.\n",
        "\n",
        "  Returns:\n",
        "      A list of dictionaries each containing a line from an abstract,\n",
        "      the lines label, the lines position in the abstract and the total number\n",
        "      of lines in the abstract where the line is from. For example:\n",
        "\n",
        "      [{\"target\": 'CONCLUSION',\n",
        "        \"text\": The study couldn't have gone better, turns out people are kinder than you think\",\n",
        "        \"line_number\": 8,\n",
        "        \"total_lines\": 8}]\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  abstract_lines = \"\" # create an empty abstract\n",
        "  abstract_samples = [] # create an empty list of abstracts\n",
        "  \n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "    \n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwmUXHrigByo"
      },
      "source": [
        "Beautiful! That's one good looking function. Let's use it to preprocess each of our RCT 20k datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDd28-PfgoUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c61c266-e007-4a25-bb61-a62f104c3bfb"
      },
      "source": [
        "# Get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 525 ms, sys: 99.1 ms, total: 624 ms\n",
            "Wall time: 621 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfFvPjTwgO7b"
      },
      "source": [
        "How do our training samples look?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcYkHrnnh0lf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05172647-a102-4e5c-8d80-54033a0d0d92"
      },
      "source": [
        "# Check the first abstract of our training data\n",
        "train_samples[:15]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 1,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'yet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .',\n",
              "  'total_lines': 10},\n",
              " {'line_number': 2,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'the aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzFwgxkQhzJS"
      },
      "source": [
        "Fantastic! Looks like our `preprocess_text_with_line_numbers()` function worked great. \n",
        "\n",
        "How about we turn our list of dictionaries into pandas DataFrame's so we visualize them better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRSTUXuth9jJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "37b5a74a-7d54-4ef0-cfe4-2f78a3460d75"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8ef4a173-c5b2-4e0f-b691-f8aad6667a47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>serum levels of interleukin @ ( il-@ ) , il-@ ...</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was a clinically relevant reduction in t...</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean difference between treatment arms ( @...</td>\n",
              "      <td>7</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>further , there was a clinically relevant redu...</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>these differences remained significant at @ we...</td>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the outcome measures in rheumatology clinical ...</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>low-dose oral prednisolone had both a short-te...</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>emotional eating is associated with overeating...</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>yet , empirical evidence for individual ( trai...</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ef4a173-c5b2-4e0f-b691-f8aad6667a47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ef4a173-c5b2-4e0f-b691-f8aad6667a47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ef4a173-c5b2-4e0f-b691-f8aad6667a47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         target  ... total_lines\n",
              "0     OBJECTIVE  ...          11\n",
              "1       METHODS  ...          11\n",
              "2       METHODS  ...          11\n",
              "3       METHODS  ...          11\n",
              "4       METHODS  ...          11\n",
              "5       METHODS  ...          11\n",
              "6       RESULTS  ...          11\n",
              "7       RESULTS  ...          11\n",
              "8       RESULTS  ...          11\n",
              "9       RESULTS  ...          11\n",
              "10      RESULTS  ...          11\n",
              "11  CONCLUSIONS  ...          11\n",
              "12   BACKGROUND  ...          10\n",
              "13   BACKGROUND  ...          10\n",
              "\n",
              "[14 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaVFf-qQg8xA"
      },
      "source": [
        "Now our data is in DataFrame form, we can perform some data analysis on it. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnQIDiJPg231",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a131db47-417d-4dc3-ec15-3bddc81b9e37"
      },
      "source": [
        "# Distribution of labels in training data\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoZbOMqUhL2l"
      },
      "source": [
        "Looks like sentences with the `OBJECTIVE` label are the least common.\n",
        "\n",
        "How about we check the distribution of our abstract lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkCRIBWbhUmD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "83aa9ba2-abc0-47fb-d7ba-8404202d06e7"
      },
      "source": [
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt2kPnlNhy0L"
      },
      "source": [
        "Okay, looks like most of the abstracts are around 7 to 15 sentences in length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqps0Jw0wcQo"
      },
      "source": [
        "### Get lists of sentences\n",
        "\n",
        "When we build our deep learning model, one of its main inputs will be a list of strings (the lines of an abstract)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybvBrdPKwmDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c90a8ef-e5e9-421d-ad65-82c7d8ef42ae"
      },
      "source": [
        "# Convert abstract text lines into lists \n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-OPWZPei46_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35c8b6ff-f1d2-4537-db06-922b39f9e346"
      },
      "source": [
        "# View first 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r36Ldgy2jDR6"
      },
      "source": [
        "We've separated our text samples. We'll have to write code to convert the text to numbers before we can use it with our machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk1tXXANaxhK"
      },
      "source": [
        "## Make numeric labels\n",
        "\n",
        "We're going to create one hot and label encoded labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riWJb105awwn",
        "outputId": "ea9bf7e6-4fdb-4cec-ca45-f8405d5ef8c4"
      },
      "source": [
        "# One hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# reshape(-1,1) >>> to change shape from (180040,) to (180040, 1)\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG-iZttkkCjL"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG8LmKhAozc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92490ed2-ddef-4030-c440-b713f4cc620b"
      },
      "source": [
        "# Extract labels (\"target\" columns) and encode them into integers \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# here no need to reshape\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd-uax-AkExg"
      },
      "source": [
        "Now we've trained an instance of `LabelEncoder`, we can get the class names and number of classes using the `classes_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeQ1OQ9glVaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754e6557-3b4a-438d-8f21-347b7715b3e7"
      },
      "source": [
        "# Get class names and number of classes from LabelEncoder instance \n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSGeXjbmlJar"
      },
      "source": [
        "## Creating a series of model experiments\n",
        "\n",
        "We've proprocessed our data so now, in true machine learning fashion, it's time to setup a series of modelling experiments.\n",
        "\n",
        "We'll start by creating a simple baseline model to obtain a score we'll try to beat by building more and more complex models as we move towards replicating the sequence model outlined in [*Neural networks for joint sentence\n",
        "classification in medical paper abstracts*](https://arxiv.org/pdf/1612.05251.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJD7X7atahFC"
      },
      "source": [
        "## Model 0: Getting a baseline \n",
        "\n",
        "Our first model we'll be a TF-IDF Multinomial Naive Bayes as recommended by [Scikit-Learn's machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n",
        "\n",
        "To build it, we'll create a Scikit-Learn `Pipeline` which uses the [`TfidfVectorizer`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class to convert our abstract sentences to numbers using the TF-IDF (term frequency-inverse document frequecy) algorithm and then learns to classify our sentences using the [`MultinomialNB`](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) aglorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km5hWlVymnxv"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences, \n",
        "            y=train_labels_encoded);"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq7BAPCmn1bM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941f328b-f176-4ec5-8b2a-d64d27ceeb04"
      },
      "source": [
        "# Evaluate baseline on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuGl9z2NjAl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409c6d11-ae3a-4f8f-e15b-1b42edfaacfb"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh2K8p3sndlG"
      },
      "source": [
        "To evaluate our baseline's predictions, we'll make the `calculate_results()` function.\n",
        "\n",
        "More specificially the `calculate_results()` function will help us obtain the following:\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "lYB5-e3TheZn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WN_TLx2jv7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89392b98-e77f-48ec-9c0f-f3351ed6b625"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MADIlN1QaiTW"
      },
      "source": [
        "## Preparing our data for deep sequence models\n",
        "\n",
        "Before we start building deeper models, we've got to create vectorization and embedding layers.\n",
        "\n",
        "* The vectorization layer will convert our text to numbers\n",
        "* The embedding layer will capture the relationships between those numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCR0F7Rhptcp"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTEPCjOuUNdj"
      },
      "source": [
        "When our model goes through our sentences, it works best when they're all the same length (this is important for creating batches of the same size tensors).\n",
        "\n",
        "We'll write some code to find the average length of sentences in the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-V_9-KrH7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c6cb00b-37c1-491b-a21c-b558c79f7234"
      },
      "source": [
        "# How long is each sentence on average? (Avg no of words)\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len # return average sentence length (in tokens)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oToFcpVTU6fU"
      },
      "source": [
        "How about the distribution of sentence lengths?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9S27ACkroai",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "6753bb97-c962-4065-85aa-df21b7c69b6a"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=100);"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH7_Yaz1U9yJ"
      },
      "source": [
        "Looks like the vast majority of sentences are between 0 and 50 tokens in length.\n",
        "\n",
        "We can use NumPy's [`percentile`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html) to find the value which covers 95% of the sentence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e5nUagxr4r5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c814e356-00ae-4187-8f38-86b0df0bab8a"
      },
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhre7MPBVfK2"
      },
      "source": [
        "It looks like 95% of the sentences in our training set have a length of 55 tokens or less.\n",
        "\n",
        "When we create our tokenization layer, we'll use this value to turn all of our sentences into the same length. Meaning sentences with a length below 55 get padded with zeros and sentences with a length above 55 get truncated (words after 55 get cut off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEZbyvh1WCBw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47449538-9783-486c-be18-24252225e8c9"
      },
      "source": [
        "# Maximum sentence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWIlFV4WF8R"
      },
      "source": [
        "Since hardly any sentences even come close to the max length, it would mean the majority of the data we pass to our model would be zeros (sinces all sentences below the max length would get padded with zeros)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvhbRw7-uMwH"
      },
      "source": [
        "### Create text vectorizer\n",
        "\n",
        "Now we've got a little more information about our texts, let's create a way to turn it into numbers.\n",
        "\n",
        "To do so, we'll use the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) layer from TensorFlow.\n",
        "\n",
        "We'll keep all the parameters default except for `max_tokens` (the number of unique words in our dataset) and `output_sequence_length` (our desired output length for each vectorized sentence).\n",
        "\n",
        "Section 3.2 of the [PubMed 200k RCT paper](https://arxiv.org/pdf/1710.06071.pdf) states the vocabulary size of the PubMed 20k dataset as 68,000. So we'll use that as our `max_tokens` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xniPYW60uzby"
      },
      "source": [
        "# How many words are in our vocabulary? (taken from 3.2 in https://arxiv.org/pdf/1710.06071.pdf)\n",
        "max_tokens = 68000"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu25jIo-YSuW"
      },
      "source": [
        "And since discovered a sentence length of 55 covers 95% of the training sentences, we'll use that as our `output_sequence_length` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtfQ27MNpy-v"
      },
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "# Create text vectorizer\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
        "                                    output_sequence_length=55) # desired output length of vectorized sequences"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbJtmyd1sWW8"
      },
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVZDwaymsbLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36dde2d6-676e-4ac0-d050-9b24eeece4db"
      },
      "source": [
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "at @ years , @ % of patients had no symptoms of angina pectoris following invasive therapy vs. @ % of patients treated with fibrinolysis ( or @ , @ % ci @-@ @ , p < @ ) .\n",
            "\n",
            "Length of text: 40\n",
            "\n",
            "Vectorized text:\n",
            "[[  15   64    4   12   55   33  144    4 1965 6363  240 1213   66   44\n",
            "     4   12  172    7 8457   16   50   14    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS80FGEhsgVe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bd7020-9bfe-41a3-e4c0-43641526fe79"
      },
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_20k_text_vocab)}\"), \n",
        "print(f\"Most common words in the vocabulary: {rct_20k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocabulary: 64841\n",
            "Most common words in the vocabulary: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocabulary: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4F6atcSa26q"
      },
      "source": [
        "And if we wanted to figure out the configuration of our `text_vectorizer` we can use the `get_config()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly5BSLkGZnPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca24f1d2-ec04-497c-e70f-6457448b0d1a"
      },
      "source": [
        "# Get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'idf_weights': None,\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'ragged': False,\n",
              " 'sparse': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZvDSTrTp1Wy"
      },
      "source": [
        "### Create custom text embedding\n",
        "\n",
        "Our `token_vectorization` layer maps the words in our text directly to numbers. However, this doesn't necessarily capture the relationships between those numbers.\n",
        "\n",
        "To create a richer numerical representation of our text, we can use an **embedding**.\n",
        "\n",
        "As our model learns (by going through many different examples of abstract sentences and their labels), it'll update its embedding to better represent the relationships between tokens in our corpus.\n",
        "\n",
        "We can create a trainable embedding layer using TensorFlow's [`Embedding`](https://www.tensorflow.org/tutorials/text/word_embeddings) layer.\n",
        "\n",
        "The main parameters we're concerned with here are the inputs and outputs of our `Embedding` layer.\n",
        "\n",
        "The `input_dim` parameter defines the size of our vocabulary. And the `output_dim` parameter defines the dimension of the embedding output.\n",
        "\n",
        "Once created, our embedding layer will take the integer outputs of our `text_vectorization` layer as inputs and convert them to feature vectors of size `output_dim`.\n",
        "\n",
        "Let's see it in action."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIKPM2QOuLQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00416861-65eb-4140-a55d-afe226957a5b"
      },
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # = length of vocabulary\n",
        "                               output_dim=128, # different embedding sizes result in different numbers of parameters to train\n",
        "                               mask_zero=True, # masking to handle variable sequence lengths (save space)\n",
        "                               name=\"token_embedding\") \n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "at @ years , @ % of patients had no symptoms of angina pectoris following invasive therapy vs. @ % of patients treated with fibrinolysis ( or @ , @ % ci @-@ @ , p < @ ) .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            "[[  15   64    4   12   55   33  144    4 1965 6363  240 1213   66   44\n",
            "     4   12  172    7 8457   16   50   14    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
            "\n",
            "Sentence after embedding:\n",
            "[[[-0.0278705  -0.03603425 -0.04056046 ...  0.00242867 -0.02890452\n",
            "    0.01117628]\n",
            "  [ 0.0114455  -0.0433684   0.02720034 ... -0.03339278  0.04268884\n",
            "    0.03211889]\n",
            "  [-0.04056257 -0.01496245  0.00353984 ...  0.00488729 -0.00093329\n",
            "    0.02935893]\n",
            "  ...\n",
            "  [ 0.03564788  0.02785869  0.00802486 ... -0.03682249 -0.04171498\n",
            "    0.01008124]\n",
            "  [ 0.03564788  0.02785869  0.00802486 ... -0.03682249 -0.04171498\n",
            "    0.01008124]\n",
            "  [ 0.03564788  0.02785869  0.00802486 ... -0.03682249 -0.04171498\n",
            "    0.01008124]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5tDy1PRfvZ0"
      },
      "source": [
        "## Create datasets (as fast as possible)\n",
        "\n",
        "There are few steps we can use to make them work faster with our models.\n",
        "\n",
        "Namely, the `tf.data` API provides methods which enable faster data loading.\n",
        "\n",
        "> ðŸ“– **Resource:**\n",
        "* [tf.data: Build TensorFlow input pipelines](https://www.tensorflow.org/guide/data)\n",
        "* [Better performance with the tf.data API](https://www.tensorflow.org/guide/data_performance)\n",
        "\n",
        "The main steps we'll want to use with our data is to turn it into a `PrefetchDataset` of batches.\n",
        "\n",
        "Doing so we'll ensure TensorFlow loads our data onto the GPU as fast as possible, in turn leading to faster training time.\n",
        "\n",
        "To create a batched `PrefetchDataset` we can use the methods [`batch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch) and [`prefetch()`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch), the parameter [`tf.data.AUTOTUNE`](https://www.tensorflow.org/api_docs/python/tf/data#AUTOTUNE) will also allow TensorFlow to determine the optimal amount of compute to use to prepare datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tan6Ekiwfza5",
        "outputId": "df974c56-395c-4b80-8d2e-8387c3b7a2fb"
      },
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnEJakTxgJWx",
        "outputId": "0576316b-f72e-4d7c-c82b-d7b8ad82d903"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeE3wo4QvOlR"
      },
      "source": [
        "## Model 1: Conv1D with token embeddings\n",
        "\n",
        "We've now got a way to numerically represent our text and labels, time to build a series of deep models to try and improve upon our baseline.\n",
        "\n",
        "All of our deep models will follow a similar structure:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)\n",
        "```\n",
        "\n",
        "The main component we'll be changing throughout is the `Layers` component. Because any modern deep NLP model requires text to be converted into an embedding before meaningful patterns can be discovered within.\n",
        "\n",
        "The first model we're going to build is a 1-dimensional Convolutional Neural Network. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTW5buTKvRR6"
      },
      "source": [
        "# Create 1D convolutional model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) # vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the output of our feature vector\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOaXSsZjnKmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e290105c-461a-469a-8f15-b4d1b3700283"
      },
      "source": [
        "# Get summary of Conv1D model\n",
        "model_1.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gZdAVJJ3vc2"
      },
      "source": [
        "We notice the majority of the trainable parameters are within the embedding layer. If we were to increase the size of the embedding (by increasing the `output_dim` parameter of the `Embedding` layer), the number of trainable parameters would increase dramatically.\n",
        "\n",
        "Since our training data contains nearly 200,000 sentences, fitting a deep model may take a while even with a GPU. So to keep our experiments swift, we're going to run them on a subset of the training dataset.\n",
        "\n",
        "More specifically, we'll only use the first 10% of batches (about 18,000 samples) of the training set to train on and the first 10% of batches from the validation set to validate on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKpHoDysgvdC",
        "outputId": "05b9dfb2-6e5c-409f-a404-1edf64c24e06"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_dataset)), # only fit on 10% of batches for faster training time\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1 * len(valid_dataset))) # only validate on 10% of batches"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 17s 14ms/step - loss: 0.9249 - accuracy: 0.6347 - val_loss: 0.6961 - val_accuracy: 0.7357\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 8s 14ms/step - loss: 0.6682 - accuracy: 0.7514 - val_loss: 0.6445 - val_accuracy: 0.7633\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.6283 - accuracy: 0.7697 - val_loss: 0.6064 - val_accuracy: 0.7809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYvFOIBvhjpX",
        "outputId": "31572e32-367e-4f0f-c8d7-1558c01c6e1d"
      },
      "source": [
        "# Evaluate on whole validation dataset (we only validated on 10% of batches during training)\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 4s 4ms/step - loss: 0.6085 - accuracy: 0.7829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6084794402122498, 0.7828677296638489]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAAtBWO2iRft",
        "outputId": "340116a6-ec2c-4883-ac32-32ab04bf3de2"
      },
      "source": [
        "# Make predictions (our model outputs prediction probabilities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.10163283e-01, 1.88139722e-01, 7.87756443e-02, 3.02386880e-01,\n",
              "        2.05344632e-02],\n",
              "       [4.49972421e-01, 2.79571205e-01, 9.76834632e-03, 2.55264878e-01,\n",
              "        5.42324269e-03],\n",
              "       [1.74588606e-01, 1.10715823e-02, 2.39079678e-03, 8.11916828e-01,\n",
              "        3.22226588e-05],\n",
              "       ...,\n",
              "       [2.65326344e-06, 9.71405127e-04, 7.12265552e-04, 2.55092527e-06,\n",
              "        9.98311162e-01],\n",
              "       [5.76577969e-02, 4.01586264e-01, 1.21813096e-01, 8.14380273e-02,\n",
              "        3.37504804e-01],\n",
              "       [2.17089564e-01, 6.00871921e-01, 4.06984016e-02, 5.44442981e-02,\n",
              "        8.68958533e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ydUpF6cqMll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad31769-bfc6-4a36-d7d9-30654805600d"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMfRLv0omdY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1073aaba-6af9-4e84-c1cc-f9e7f094eb35"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.28677346749636,\n",
              " 'f1': 0.780498869178265,\n",
              " 'precision': 0.7793790019798815,\n",
              " 'recall': 0.7828677346749636}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU1u4KlWvAQa"
      },
      "source": [
        "## Model 2: Feature extraction with pretrained token embeddings\n",
        "\n",
        "Since we're moving towards replicating the model architecture in [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), it mentions they used a [pretrained GloVe embedding](https://nlp.stanford.edu/projects/glove/) as a way to initialise their token embeddings.\n",
        "\n",
        "To emulate this, let's see what results we can get with the [pretrained Universal Sentence Encoder embeddings from TensorFlow Hub](https://tfhub.dev/google/universal-sentence-encoder/4).\n",
        "\n",
        "The model structure will look like:\n",
        "\n",
        "```\n",
        "Inputs (string) -> Pretrained embeddings from TensorFlow Hub (Universal Sentence Encoder) -> Layers -> Output (prediction probabilities)\n",
        "```\n",
        "\n",
        "The Universal Sentence Encoder (USE) takes care of tokenization for us.\n",
        "\n",
        "To download the pretrained USE into a layer we can use in our model, we can use the [`hub.KerasLayer`](https://www.tensorflow.org/hub/api_docs/python/hub/KerasLayer) class.\n",
        "\n",
        "We'll keep the pretrained embeddings frozen (by setting `trainable=False`) and add a trainable couple of layers on the top to tailor the model outputs to our own data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk8mJUNy0xOO"
      },
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5gCkZgYJYSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f3d744-99c6-46bd-8e1a-4ed08fa34b06"
      },
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random training sentence:\n",
            "however , supplementation of carbohydrates before surgery attenuates the post-operative insulin resistance .\n",
            "\n",
            "Sentence after embedding:\n",
            "[-0.01909025  0.00963744  0.01162192 -0.03343723 -0.053842    0.05463621\n",
            "  0.02472959  0.01508655  0.00132836  0.06591532  0.08021165  0.00282375\n",
            "  0.02893527  0.04497205 -0.08179849  0.01019921 -0.08454854 -0.05728979\n",
            " -0.00956765  0.02844423  0.0449668   0.06593847  0.04358137  0.06355283\n",
            "  0.06051598  0.00164153  0.0520772   0.04944831  0.02990491 -0.05852894] (truncated output)...\n",
            "\n",
            "Length of sentence embedding:\n",
            "512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rB98xmH4KO-0"
      },
      "source": [
        "The pretrained USE module from TensorFlow Hub takes care of tokenizing our text for us and outputs a 512 dimensional embedding vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJue6QIthOZD"
      },
      "source": [
        "### Building and fitting an NLP feature extraction model from TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So4lSnW_2F1i"
      },
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39r3jhefoKWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c166d10-6b9f-469c-a196-938a6aac0da2"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttJKg6cDihGd",
        "outputId": "c1470a80-06c9-4c0e-9d53-6a2ba0b01be1"
      },
      "source": [
        "# Fit feature extractor model for 3 epochs\n",
        "model_2.fit(train_dataset,\n",
        "            steps_per_epoch=int(0.1 * len(train_dataset)),\n",
        "            epochs=3,\n",
        "            validation_data=valid_dataset,\n",
        "            validation_steps=int(0.1 * len(valid_dataset)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 13s 19ms/step - loss: 0.9175 - accuracy: 0.6477 - val_loss: 0.7944 - val_accuracy: 0.6892\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.7686 - accuracy: 0.7029 - val_loss: 0.7541 - val_accuracy: 0.7045\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 10s 18ms/step - loss: 0.7531 - accuracy: 0.7109 - val_loss: 0.7380 - val_accuracy: 0.7131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27b6314410>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz8TMzLrjJYm",
        "outputId": "f65f1a9d-d082-4ac1-ea34-a0fc524b1369"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 15s 16ms/step - loss: 0.7413 - accuracy: 0.7138\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7413089871406555, 0.7138223052024841]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oe5UxcgqvA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63b59f9e-a944-4d25-b3fd-1e28afaa665c"
      },
      "source": [
        "# Make predictions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.40846723, 0.363591  , 0.00264925, 0.21553276, 0.00975978],\n",
              "       [0.34387004, 0.5008134 , 0.00514823, 0.14604759, 0.00412075],\n",
              "       [0.20934962, 0.13439812, 0.01952453, 0.59732145, 0.03940623],\n",
              "       ...,\n",
              "       [0.00187489, 0.00600175, 0.05850172, 0.00102283, 0.9325988 ],\n",
              "       [0.00331286, 0.04362445, 0.18586498, 0.00120968, 0.765988  ],\n",
              "       [0.15707995, 0.22806749, 0.5597769 , 0.00651355, 0.04856216]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8RIEnvVq7Ri",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca822dd3-b996-488b-ec42-2c974d8fed3f"
      },
      "source": [
        "# Convert the predictions with feature extraction model to classes\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hD5yvw9brOCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66d629f0-e588-4e13-9ad8-9e04d965e746"
      },
      "source": [
        "# Calculate results from TF Hub pretrained embeddings results on validation set\n",
        "model_2_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.38223222560572,\n",
              " 'f1': 0.7107433271779462,\n",
              " 'precision': 0.7142437493728919,\n",
              " 'recall': 0.7138223222560572}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EL6wApSH0ltW"
      },
      "source": [
        "## Model 3: Conv1D with character embeddings\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-q-BYLq6d1me"
      },
      "source": [
        "### Creating a character-level tokenizer\n",
        "\n",
        "The [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) paper mentions their model uses a hybrid of token and character embeddings.\n",
        "\n",
        "The difference between a character and token embedding is that the **character embedding** is created using sequences split into characters (e.g. `hello` -> [`h`, `e`, `l`, `l`, `o`]) where as a **token embedding** is created on sequences split into tokens.\n",
        "\n",
        "![example of difference between token level and character level embeddings](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-token-vs-character-embeddings.png)\n",
        "*Token level embeddings split sequences into tokens (words) and embeddings each of them, character embeddings split sequences into characters and creates a feature vector for each.*\n",
        "\n",
        "We can create a character-level embedding by first vectorizing our sequences (after they've been split into characters) using the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class and then passing those vectorized sequences through an [`Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) layer.\n",
        "\n",
        "Before we can vectorize our sequences on a character-level we'll need to split them into characters. Let's write a function to do so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkoTYNvu36Bq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "72a8c285-6ed6-4437-fe8c-e8d096e44c17"
      },
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'h o w e v e r   ,   s u p p l e m e n t a t i o n   o f   c a r b o h y d r a t e s   b e f o r e   s u r g e r y   a t t e n u a t e s   t h e   p o s t - o p e r a t i v e   i n s u l i n   r e s i s t a n c e   .'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyfYyWOvx2BB"
      },
      "source": [
        "Great! Looks like our character-splitting function works. Let's create character-level datasets by splitting our sequence datasets into characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLmU_GS64S2J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "caffa861-3d56-423f-aad2-3d9743d131ec"
      },
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t o   i n v e s t i g a t e   t h e   e f f i c a c y   o f   @   w e e k s   o f   d a i l y   l o w - d o s e   o r a l   p r e d n i s o l o n e   i n   i m p r o v i n g   p a i n   ,   m o b i l i t y   ,   a n d   s y s t e m i c   l o w - g r a d e   i n f l a m m a t i o n   i n   t h e   s h o r t   t e r m   a n d   w h e t h e r   t h e   e f f e c t   w o u l d   b e   s u s t a i n e d   a t   @   w e e k s   i n   o l d e r   a d u l t s   w i t h   m o d e r a t e   t o   s e v e r e   k n e e   o s t e o a r t h r i t i s   (   o a   )   .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkLTb7FkyFPh"
      },
      "source": [
        "To figure out how long our vectorized character sequences should be, let's check the distribution of our character sequence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CjyFW5g47Ps",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9854a2b-1405-4c5f-fa3a-3a6c96a3662d"
      },
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "149.3662574983337"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPTgrtVJ2DSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "97d425bd-1d01-426d-d91f-ca12d2dc3571"
      },
      "source": [
        "# Check the distribution of our sequences at character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=100);"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV8yNV6l1hO4"
      },
      "source": [
        "Okay, looks like most of our sequences are between 0 and 200 characters long.\n",
        "\n",
        "Let's use NumPy's percentile to figure out what length covers 95% of our sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_k46x0Wy2n9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a9e26a-8575-40cc-d509-93121058b43e"
      },
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "290"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dDBUHMT3QwS"
      },
      "source": [
        "Now we know the sequence length which covers 95% of sequences, we'll use that in our `TextVectorization` layer as the `output_sequence_length` parameter.\n",
        "\n",
        "We'll set `max_tokens` (the total number of different characters in our sequences) to 28, in other words, 26 letters of the alphabet + space + OOV (out of vocabulary or unknown) tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "a7uKkbP_irFg",
        "outputId": "e1ee811a-5791-48fa-abea-a86c6e075468"
      },
      "source": [
        "# Get all keyboard characters for char-level embedding\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTMInkbv4Jxi"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,  \n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxdh7gxv5R4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6333b01-db39-4ea8-b322-0f0275bb0b15"
      },
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters: ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFYO0vav51zl"
      },
      "source": [
        "We can also test it on random sequences of characters to make sure it's working."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAcasGEh5d2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd095ab-55c7-4dcc-d4f7-673f4c027f35"
      },
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            "p r e g a b a l i n   w a s   j u s t   s i g n i f i c a n t l y   e f f e c t i v e   i n   i m p r o v i n g   p c l - m   s c o r e s   (   p   =   @   )   i n   c o m p a r i s o n   t o   p l a c e b o   .\n",
            "\n",
            "Length of chars: 88\n",
            "\n",
            "Vectorized chars:\n",
            "[[14  8  2 18  5 22  5 12  4  6 20  5  9 27 16  9  3  9  4 18  6  4 17  4\n",
            "  11  5  6  3 12 19  2 17 17  2 11  3  4 21  2  4  6  4 15 14  8  7 21  4\n",
            "   6 18 14 11 12 15  9 11  7  8  2  9 14  4  6 11  7 15 14  5  8  4  9  7\n",
            "   6  3  7 14 12  5 11  2 22  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0]]\n",
            "\n",
            "Length of vectorized chars: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT_OiBd_6j8W"
      },
      "source": [
        "Due to the `standardize` parameter of `TextVectorization` being `\"lower_and_strip_punctuation\"` and the `split` parameter being `\"whitespace\"` by default, symbols (such as `@`) and spaces are removed.\n",
        "\n",
        "> ðŸ”‘ **Note:** If you didn't want punctuation to be removed (keep the `@`, `%` etc), you can create a custom standardization callable and pass it as the `standardize` parameter. See the [`TextVectorization`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing/TextVectorization) class documentation for more.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8WEfkrDeNIm"
      },
      "source": [
        "### Creating a character-level embedding\n",
        "We've got a way to vectorize our character-level sequences, now's time to create a character-level embedding.\n",
        "\n",
        "Just like our custom token embedding, we can do so using the [`tensorflow.keras.layers.Embedding`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding) class.\n",
        "\n",
        "Our character-level embedding layer requires an input dimension and output dimension. \n",
        "\n",
        "The input dimension (`input_dim`) will be equal to the number of different characters in our `char_vocab` (28). And since we're following the structure of the model in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf), the output dimension of the character embedding (`output_dim`) will be 25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQHt1hSy57cu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59725b95-694c-4af9-ea24-b3ae099cb406"
      },
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text (before vectorization and embedding):\n",
            "p r e g a b a l i n   w a s   j u s t   s i g n i f i c a n t l y   e f f e c t i v e   i n   i m p r o v i n g   p c l - m   s c o r e s   (   p   =   @   )   i n   c o m p a r i s o n   t o   p l a c e b o   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            "[[[-0.00708338  0.0391033  -0.0125519  ...  0.00456725  0.03536024\n",
            "    0.04412991]\n",
            "  [ 0.0114238  -0.04669143  0.02824876 ... -0.04509372 -0.00375073\n",
            "   -0.02115341]\n",
            "  [-0.0185848  -0.01344751  0.02363713 ... -0.00851057 -0.0175378\n",
            "    0.00944465]\n",
            "  ...\n",
            "  [ 0.04733027 -0.03404155 -0.0224415  ...  0.00257114 -0.03612649\n",
            "    0.00370397]\n",
            "  [ 0.04733027 -0.03404155 -0.0224415  ...  0.00257114 -0.03612649\n",
            "    0.00370397]\n",
            "  [ 0.04733027 -0.03404155 -0.0224415  ...  0.00257114 -0.03612649\n",
            "    0.00370397]]]\n",
            "\n",
            "Character embedding shape: (1, 290, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bzv_FmFd9bN"
      },
      "source": [
        "### Building a Conv1D model to fit on character embeddings\n",
        "The model will have the same structure as our custom token embedding model (`model_1`) except it'll take character-level sequences as input instead of token-level sequences.\n",
        "\n",
        "```\n",
        "Input (character-level text) -> Tokenize -> Embedding -> Layers (Conv1D, GlobalMaxPool1D) -> Output (label probability)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVwC0xadtb5r"
      },
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1D_char_embedding\")\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwdxy2gQu7Wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c0068f-6ece-4500-9750-abf4e2f025b0"
      },
      "source": [
        "# Check the summary of conv1d_char_model\n",
        "model_3.summary()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_conv1D_char_embedding\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " char_vectorizer (TextVector  (None, 290)              0         \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " char_embed (Embedding)      (None, 290, 25)           1750      \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 290, 64)           8064      \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,139\n",
            "Trainable params: 10,139\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sr9rNkxAkURZ"
      },
      "source": [
        "Before fitting our model on the data, we'll create char-level batched `PrefetchedDataset`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixTsGYBbnXn9",
        "outputId": "821d22cc-798a-4ce2-fe64-bc561590b985"
      },
      "source": [
        "# Create char datasets\n",
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qpv1NR_cC1h"
      },
      "source": [
        "Just like our token-level sequence model, to save time with our experiments, we'll fit the character-level model on 10% of batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGokmMdGn91w",
        "outputId": "67e31b1b-d982-4c12-ba6c-b3137b46a454"
      },
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_dataset)))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 6s 10ms/step - loss: 1.2764 - accuracy: 0.4843 - val_loss: 1.0429 - val_accuracy: 0.5775\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 5s 9ms/step - loss: 0.9993 - accuracy: 0.5990 - val_loss: 0.9412 - val_accuracy: 0.6213\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 5s 9ms/step - loss: 0.9201 - accuracy: 0.6376 - val_loss: 0.8709 - val_accuracy: 0.6569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHO-fl9oA5V",
        "outputId": "675b4602-665d-4391-9107-92d4068b5483"
      },
      "source": [
        "# Evaluate model_3 on whole validation char dataset\n",
        "model_3.evaluate(val_char_dataset)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 5s 5ms/step - loss: 0.8851 - accuracy: 0.6527\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.885052502155304, 0.6527207493782043]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0u4QzT2xMgF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbdf702-499a-4af6-9cf1-e2b1287df3b8"
      },
      "source": [
        "# Make predictions with character model only\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2215139 , 0.25792092, 0.09467394, 0.3978184 , 0.02807294],\n",
              "       [0.20431207, 0.50166404, 0.01734403, 0.1618705 , 0.11480931],\n",
              "       [0.12680057, 0.40359762, 0.07490539, 0.31011885, 0.08457761],\n",
              "       ...,\n",
              "       [0.01800892, 0.02651619, 0.21263584, 0.01756434, 0.72527474],\n",
              "       [0.01153296, 0.11483295, 0.21047859, 0.0166051 , 0.6465505 ],\n",
              "       [0.3656156 , 0.34484872, 0.21229221, 0.06035734, 0.01688611]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdPUXiZux68-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b5367f-92f5-4162-b7aa-cbbd743b21dd"
      },
      "source": [
        "# Convert predictions to classes\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([3, 1, 1, ..., 4, 4, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NCDZD7cyoj7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbcf5b4-501a-422c-95c9-5c7be93184f6"
      },
      "source": [
        "# Calculate Conv1D char only model results\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                        y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 65.2720773202701,\n",
              " 'f1': 0.6406867652324811,\n",
              " 'precision': 0.6435390008945217,\n",
              " 'recall': 0.6527207732027009}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1krE-3csz3N-"
      },
      "source": [
        "## Model 4: Combining pretrained token embeddings + character embeddings (hybrid embedding layer)\n",
        "\n",
        "In moving closer to build a model similar to the one in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf).\n",
        "\n",
        "![fig_1](https://github.com/abdrahmansoltan/Skimit/blob/main/assets/Figure_1.PNG?raw=true)\n",
        "\n",
        "*Figure 1: ANN model for sequential sentence classification.*\n",
        "\n",
        "This hybrid token embedding layer is a combination of token embeddings and character embeddings. In other words, they create a stacked embedding to represent sequences before passing them to the sequence label prediction layer.\n",
        "\n",
        "To start replicating (or getting close to replicating) the model in Figure 1, we're going to go through the following steps:\n",
        "1. Create a token-level model (similar to `model_1`)\n",
        "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
        "3. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2\n",
        "4. Build a series of output layers on top of 3 similar to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "5. Construct a model which takes token and character-level sequences as input and produces sequence label probabilities as output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DI2KQf7z-yo"
      },
      "source": [
        "# 1. Setup token inputs/model\n",
        "token_inputs = layers.Input(shape=[], dtype=tf.string, name=\"token_input\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_output = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_output)\n",
        "\n",
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Concatenate token and char inputs (create hybrid token embedding)\n",
        "token_char_concat = layers.Concatenate(name=\"token_char_hybrid\")([token_model.output, \n",
        "                                                                  char_model.output])\n",
        "\n",
        "# 4. Create output layers - addition of dropout discussed in 4.2 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "combined_dropout = layers.Dropout(0.5)(token_char_concat)\n",
        "combined_dense = layers.Dense(200, activation=\"relu\")(combined_dropout) # slightly different to Figure 1 due to different shapes of token/char embedding layers\n",
        "final_dropout = layers.Dropout(0.5)(combined_dense)\n",
        "output_layer = layers.Dense(num_classes, activation=\"softmax\")(final_dropout)\n",
        "\n",
        "# 5. Construct model with char and token inputs\n",
        "model_4 = tf.keras.Model(inputs=[token_model.input, char_model.input],\n",
        "                         outputs=output_layer,\n",
        "                         name=\"model_4_token_and_char_embeddings\")"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21PRnEmK2a0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b964f961-14b8-4d6e-d574-ea0deebaa09d"
      },
      "source": [
        "# Get summary of token and character model\n",
        "model_4.summary()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_token_and_char_embeddings\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_input (InputLayer)        [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " token_input (InputLayer)       [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_input[0][0]']             \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_input[0][0]']            \n",
            " rasLayer)                                                                                        \n",
            "                                                                                                  \n",
            " char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[1][0]']        \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[1][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " bidirectional (Bidirectional)  (None, 50)           10200       ['char_embed[1][0]']             \n",
            "                                                                                                  \n",
            " token_char_hybrid (Concatenate  (None, 178)         0           ['dense_4[0][0]',                \n",
            " )                                                                'bidirectional[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 178)          0           ['token_char_hybrid[0][0]']      \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 200)          35800       ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 200)          0           ['dense_5[0][0]']                \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 5)            1005        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 256,912,243\n",
            "Trainable params: 114,419\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF5-v5cRSmuk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "520f5ffb-b7b4-4959-f4e8-1e26f81fe672"
      },
      "source": [
        "# Plot hybrid token and character model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_4)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPPfr_cTWmEH"
      },
      "source": [
        "Now that's a good looking model. Let's compile it just as we have the rest of our models.\n",
        "\n",
        ">**Note:** Section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf) mentions using the SGD (stochastic gradient descent) optimizer, however, to stay consistent with our other models, we're going to use the Adam optimizer. As an exercise, you could try using [`tf.keras.optimizers.SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) instead of [`tf.keras.optimizers.Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam) and compare the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yx8PFSc2hqE"
      },
      "source": [
        "# Compile token char model\n",
        "model_4.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(), # section 4.2 of https://arxiv.org/pdf/1612.05251.pdf mentions using SGD but we'll stick with Adam\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-bD7bL-UIn3"
      },
      "source": [
        "We'll fit our token-character-hybrid model on 10% of training and validate on 10% of validation batches. However, the difference with this model is that it requires two inputs, token-level sequences and character-level sequences.\n",
        "\n",
        "We can do this by create a `tf.data.Dataset` with a tuple as it's first input, for example:\n",
        "* `((token_data, char_data), (label))`\n",
        "\n",
        "Let's see it in action.\n",
        "\n",
        "### Combining token and character data into a `tf.data` dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYU0fX6rpbgI"
      },
      "source": [
        "# Combine chars and tokens into a dataset\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) \n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlOs99Emp52r",
        "outputId": "d744d84e-18fd-4ad4-e418-913d0e81c710"
      },
      "source": [
        "# Check out training char and token embedding dataset\n",
        "train_char_token_dataset, val_char_token_dataset"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None,), (None,)), (None, 5)), types: ((tf.string, tf.string), tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANLBMpRlfA73"
      },
      "source": [
        "### Fitting a model on token and character-level sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0c25coprwp",
        "outputId": "b1099881-61ce-47df-d01a-e7a4ecd1a23d"
      },
      "source": [
        "# Fit the model on tokens and chars\n",
        "model_4_history = model_4.fit(train_char_token_dataset, # train on dataset of token and characters\n",
        "                              steps_per_epoch=int(0.1 * len(train_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_char_token_dataset)))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 73s 120ms/step - loss: 0.9701 - accuracy: 0.6125 - val_loss: 0.7744 - val_accuracy: 0.7028\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 66s 118ms/step - loss: 0.7986 - accuracy: 0.6921 - val_loss: 0.7189 - val_accuracy: 0.7297\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 66s 118ms/step - loss: 0.7692 - accuracy: 0.7031 - val_loss: 0.6877 - val_accuracy: 0.7360\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfAMuoJett_t",
        "outputId": "9545122e-1e36-430f-9bec-1f8585a8e21f"
      },
      "source": [
        "# Evaluate on the whole validation dataset\n",
        "model_4.evaluate(val_char_token_dataset)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 49s 52ms/step - loss: 0.6926 - accuracy: 0.7320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6925626397132874, 0.732026994228363]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1z_zbrXTYN7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6552be6e-d03d-48ce-ecdf-cddfe38a4133"
      },
      "source": [
        "# Make predictions using the token-character model hybrid\n",
        "model_4_pred_probs = model_4.predict(val_char_token_dataset)\n",
        "model_4_pred_probs"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.3110290e-01, 3.6049640e-01, 5.8239228e-03, 1.9448379e-01,\n",
              "        8.0930563e-03],\n",
              "       [3.0234355e-01, 5.3326124e-01, 4.9240915e-03, 1.5780823e-01,\n",
              "        1.6628662e-03],\n",
              "       [2.7031657e-01, 1.7427759e-01, 6.2983595e-02, 4.5421022e-01,\n",
              "        3.8212076e-02],\n",
              "       ...,\n",
              "       [3.9873188e-04, 6.4095771e-03, 3.9857339e-02, 1.6672659e-04,\n",
              "        9.5316762e-01],\n",
              "       [6.6495077e-03, 6.5696761e-02, 2.1893609e-01, 3.1612024e-03,\n",
              "        7.0555645e-01],\n",
              "       [2.6624748e-01, 4.7719061e-01, 2.1374796e-01, 1.2739683e-02,\n",
              "        3.0074300e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic5MCrFxYgsB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6719b1-29ce-4ab1-8a05-0deb74b45677"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_4_preds = tf.argmax(model_4_pred_probs, axis=1)\n",
        "model_4_preds"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBNPIRIC7EsE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814e43e4-0fa5-477a-c587-4c579addcee1"
      },
      "source": [
        "# Get results of token-char-hybrid model\n",
        "model_4_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 73.20270091354428,\n",
              " 'f1': 0.7292464447068681,\n",
              " 'precision': 0.7325310461100402,\n",
              " 'recall': 0.7320270091354428}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU5ctbxCih6Z"
      },
      "source": [
        "## Model 5: Transfer Learning with pretrained token embeddings + character embeddings + positional embeddings \n",
        "\n",
        "It seems like combining token embeddings and character embeddings gave our model a little performance boost.\n",
        "\n",
        "### Feature engineering.\n",
        "\n",
        "If you were to look at an abstract, would you expect the sentences to appear in order? Or does it make sense if they were to appear sequentially? For example, sequences labelled `CONCLUSIONS` at the beggining and sequences labelled `OBJECTIVE` at the end?\n",
        "\n",
        "Abstracts typically come in a sequential order, such as:\n",
        "* `OBJECTIVE` ...\n",
        "* `METHODS` ...\n",
        "* `METHODS` ...\n",
        "* `METHODS` ...\n",
        "* `RESULTS` ...\n",
        "* `CONCLUSIONS` ...\n",
        "\n",
        "Or\n",
        "\n",
        "* `BACKGROUND` ...\n",
        "* `OBJECTIVE` ...\n",
        "* `METHODS` ...\n",
        "* `METHODS` ...\n",
        "* `RESULTS` ...\n",
        "* `RESULTS` ...\n",
        "* `CONCLUSIONS` ...\n",
        "* `CONCLUSIONS` ...\n",
        "\n",
        "We can encode the order of a set of sequences in an abstract.\n",
        "\n",
        "For example,\n",
        "* `Sentence 1 of 10` ...\n",
        "* `Sentence 2 of 10` ...\n",
        "* `Sentence 3 of 10` ...\n",
        "* `Sentence 4 of 10` ...\n",
        "* ...\n",
        "\n",
        "\n",
        "When we created our `preprocess_text_with_line_numbers()` function. When we read in a text file of abstracts, we counted the number of lines in an abstract as well as the number of each line itself.\n",
        "\n",
        "Doing this led to the `\"line_number\"` and `\"total_lines\"` columns of our DataFrames."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htf-tnFcEcAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "dc7e7e47-6e1f-4719-b945-bb4d62e4668c"
      },
      "source": [
        "# Inspect training dataframe\n",
        "train_df.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-39afa697-fe44-48be-b8ce-c0d6fe562084\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39afa697-fe44-48be-b8ce-c0d6fe562084')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39afa697-fe44-48be-b8ce-c0d6fe562084 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39afa697-fe44-48be-b8ce-c0d6fe562084');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      target  ... total_lines\n",
              "0  OBJECTIVE  ...          11\n",
              "1    METHODS  ...          11\n",
              "2    METHODS  ...          11\n",
              "3    METHODS  ...          11\n",
              "4    METHODS  ...          11\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ5HvKoiGU6m"
      },
      "source": [
        "The `\"line_number\"` and `\"total_lines\"` columns are features which didn't necessarily come with the training data but can be passed to our model as a **positional embedding**. In other words, the positional embedding is where the sentence appears in an abstract.\n",
        "\n",
        "We can use these features because they will be available at test time. \n",
        "\n",
        "![example of engineering features into our dataset to help our model](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/09-engineered-features-at-test-time.png)\n",
        "*Since abstracts typically have a sequential order about them (for example, background, objective, methods, results, conclusion), it makes sense to add the line number of where a particular sentence occurs to our model.*\n",
        "\n",
        "Meaning, if we were to predict the labels of sequences in an abstract our model had never seen, we could count the number of lines and the track the position of each individual line and pass it to our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABuz5baDJwY-"
      },
      "source": [
        "### Create positional embeddings\n",
        "\n",
        "Okay, enough talk about positional embeddings, let's create them.\n",
        "\n",
        "Since our `\"line_number\"` and `\"total_line\"` columns are already numerical, we could pass them as they are to our model.\n",
        "\n",
        "But to avoid our model thinking a line with `\"line_number\"=5` is five times greater than a line with `\"line_number\"=1`, we'll use one-hot-encoding to encode our `\"line_number\"` and `\"total_lines\"` features.\n",
        "\n",
        "To do this, we can use the [`tf.one_hot`](https://www.tensorflow.org/api_docs/python/tf/one_hot) utility.\n",
        "\n",
        "`tf.one_hot` returns a one-hot-encoded tensor. It accepts an array (or tensor) as input and the `depth` parameter determines the dimension of the returned tensor.\n",
        "\n",
        "To figure out what we should set the `depth` parameter to, let's investigate the distribution of the `\"line_number\"` column.\n",
        "\n",
        "> ðŸ”‘ **Note:** When it comes to one-hot-encoding our features, Scikit-Learn's [`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) class is another viable option here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVhuU7cMd0-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b104054-ba9d-4569-dc0a-4519256b7f5d"
      },
      "source": [
        "# How many different line numbers are there?\n",
        "train_df[\"line_number\"].value_counts()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     15000\n",
              "1     15000\n",
              "2     15000\n",
              "3     15000\n",
              "4     14992\n",
              "5     14949\n",
              "6     14758\n",
              "7     14279\n",
              "8     13346\n",
              "9     11981\n",
              "10    10041\n",
              "11     7892\n",
              "12     5853\n",
              "13     4152\n",
              "14     2835\n",
              "15     1861\n",
              "16     1188\n",
              "17      751\n",
              "18      462\n",
              "19      286\n",
              "20      162\n",
              "21      101\n",
              "22       66\n",
              "23       33\n",
              "24       22\n",
              "25       14\n",
              "26        7\n",
              "27        4\n",
              "28        3\n",
              "29        1\n",
              "30        1\n",
              "Name: line_number, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKoNMSBNImLG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "0fd0693e-d05f-4123-f7cb-e47abe8ecc1b"
      },
      "source": [
        "# Check the distribution of \"line_number\" column\n",
        "train_df.line_number.plot.hist()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f279e832350>"
            ]
          },
          "metadata": {},
          "execution_count": 85
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPnEkJvXKuf9"
      },
      "source": [
        "Looking at the distribution of the `\"line_number\"` column, it looks like the majority of lines have a position of 15 or less.\n",
        "\n",
        "Knowing this, let's set the `depth` parameter of `tf.one_hot` to 15."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsjdKcXUMkgE"
      },
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column \n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MTRSo_OLWGS"
      },
      "source": [
        "Setting the `depth` parameter of `tf.one_hot` to 15 means any sample with a `\"line_number\"` value of over 15 gets set to a tensor of all 0's, where as any sample with a `\"line_number\"` of under 15 gets turned into a tensor of all 0's but with a 1 at the index equal to the `\"line_number\"` value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7BERNOQK723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b728168-3510-4b7f-f419-5c0855589ca5"
      },
      "source": [
        "# Check one-hot encoded \"line_number\" feature samples\n",
        "train_line_numbers_one_hot.shape, train_line_numbers_one_hot[:20]"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 15]), <tf.Tensor: shape=(20, 15), dtype=float32, numpy=\n",
              " array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "       dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxYgKu6tMBbg"
      },
      "source": [
        "We can do the same as we've done for our `\"line_number\"` column witht he `\"total_lines\"` column. First, let's find an appropriate value for the `depth` parameter of `tf.one_hot`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3bLbdWzOBmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa6f3082-7acf-49d2-9df2-5ef72d05d6dd"
      },
      "source": [
        "# How many different numbers of lines are there?\n",
        "train_df[\"total_lines\"].value_counts()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: total_lines, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxDN9ASLL9uY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "0c197d38-13fe-4db7-f5df-abc5be0b078e"
      },
      "source": [
        "# Check the distribution of total lines\n",
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBWX2cIHN_1J"
      },
      "source": [
        "Looking at the distribution of our `\"total_lines\"` column, a value of 20 looks like it covers the majority of samples.\n",
        "\n",
        "We can confirm this with [`np.percentile()`](https://numpy.org/doc/stable/reference/generated/numpy.percentile.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or736pZLNwWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d702000a-4f64-4ada-e0f1-cea9621d5baf"
      },
      "source": [
        "# Check the coverage of a \"total_lines\" value of 20\n",
        "np.percentile(train_df.total_lines, 98) # a value of 20 covers 98% of samples"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.0"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egqq3LnnN0Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0189e1bf-4529-4bd0-f4e6-4c90f3c03db8"
      },
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column \n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Check shape and samples of total lines one-hot tensor\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([180040, 20]), <tf.Tensor: shape=(10, 20), dtype=float32, numpy=\n",
              " array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "         0., 0., 0., 0.]], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVJWCANtQMiJ"
      },
      "source": [
        "### Building a tribrid embedding model\n",
        "\n",
        "We'll build a model which incorporates token embeddings, character embeddings and our newly crafted positional embeddings.\n",
        "\n",
        "We're going to go through the following steps:\n",
        "\n",
        "1. Create a token-level model (similar to `model_1`)\n",
        "2. Create a character-level model (similar to `model_3` with a slight modification to reflect the paper)\n",
        "3. Create a `\"line_number\"` model (takes in one-hot-encoded `\"line_number\"` tensor and passes it through a non-linear layer)\n",
        "4. Create a `\"total_lines\"` model (takes in one-hot-encoded `\"total_lines\"` tensor and passes it through a non-linear layer)\n",
        "5. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 1 and 2 into a token-character-hybrid embedding and pass it series of output to Figure 1 and section 4.2 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf)\n",
        "6. Combine (using [`layers.Concatenate`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate)) the outputs of 3, 4 and 5 into a token-character-positional tribrid embedding \n",
        "7. Create an output layer to accept the tribrid embedding and output predicted label probabilities\n",
        "8. Combine the inputs of 1, 2, 3, 4 and outputs of 7 into a [`tf.keras.Model`](https://www.tensorflow.org/api_docs/python/tf/keras/Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPiFnY8E0oPS"
      },
      "source": [
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input, \n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7eJOhlKfVQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9204497c-bb26-4a24-e44c-5929d355c84b"
      },
      "source": [
        "# Get a summary of our token, char and positional embedding model\n",
        "model_5.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " char_inputs (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " token_inputs (InputLayer)      [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " char_vectorizer (TextVectoriza  (None, 290)         0           ['char_inputs[0][0]']            \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " universal_sentence_encoder (Ke  (None, 512)         256797824   ['token_inputs[0][0]']           \n",
            " rasLayer)                                                                                        \n",
            "                                                                                                  \n",
            " char_embed (Embedding)         (None, 290, 25)      1750        ['char_vectorizer[2][0]']        \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 128)          65664       ['universal_sentence_encoder[2][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirectional  (None, 64)          14848       ['char_embed[2][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " token_char_hybrid_embedding (C  (None, 192)         0           ['dense_7[0][0]',                \n",
            " oncatenate)                                                      'bidirectional_1[0][0]']        \n",
            "                                                                                                  \n",
            " line_number_input (InputLayer)  [(None, 15)]        0           []                               \n",
            "                                                                                                  \n",
            " total_lines_input (InputLayer)  [(None, 20)]        0           []                               \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 256)          49408       ['token_char_hybrid_embedding[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 32)           512         ['line_number_input[0][0]']      \n",
            "                                                                                                  \n",
            " dense_9 (Dense)                (None, 32)           672         ['total_lines_input[0][0]']      \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 256)          0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " token_char_positional_embeddin  (None, 320)         0           ['dense_8[0][0]',                \n",
            " g (Concatenate)                                                  'dense_9[0][0]',                \n",
            "                                                                  'dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " output_layer (Dense)           (None, 5)            1605        ['token_char_positional_embedding\n",
            "                                                                 [0][0]']                         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 256,932,283\n",
            "Trainable params: 134,459\n",
            "Non-trainable params: 256,797,824\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM0dohpZ_v5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 855
        },
        "outputId": "cc7adacd-64fb-4de4-9f20-47e798e7fdaf"
      },
      "source": [
        "# Plot the token, char, positional embedding model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model_5)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8B73w06Wxxm"
      },
      "source": [
        "Essentially what we're doing is trying to encode as much information about our sequences as possible into various embeddings (the inputs to our model) so our model has the best chance to figure out what label belongs to a sequence (the outputs of our model).\n",
        "\n",
        "You'll notice our model is looking very similar to the model shown in Figure 1 of [*Neural Networks for Joint Sentence Classification\n",
        "in Medical Paper Abstracts*](https://arxiv.org/pdf/1612.05251.pdf). However, a few differences still remain:\n",
        "* We're using pretrained TensorFlow Hub token embeddings instead of GloVe emebddings.\n",
        "* We're using a Dense layer on top of our token-character hybrid embeddings instead of a bi-LSTM layer.\n",
        "* Section 3.1.3 of the paper mentions a label sequence optimization layer (which helps to make sure sequence labels come out in a respectable order) but it isn't shown in Figure 1. To makeup for the lack of this layer in our model, we've created the positional embeddings layers.\n",
        "* Section 4.2 of the paper mentions the token and character embeddings are updated during training, our pretrained TensorFlow Hub embeddings remain frozen.\n",
        "* The paper uses the [`SGD`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD) optimizer, we're going to stick with [`Adam`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud8arQOTUtRl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d086c04-de81-4b99-d543-28a87b9be527"
      },
      "source": [
        "# Check which layers of our model are trainable or not\n",
        "for layer in model_5.layers:\n",
        "  print(layer, layer.trainable)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.engine.input_layer.InputLayer object at 0x7f27b02e49d0> True\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f279df81dd0> True\n",
            "<keras.layers.preprocessing.text_vectorization.TextVectorization object at 0x7f2924324e90> True\n",
            "<tensorflow_hub.keras_layer.KerasLayer object at 0x7f282ccd0590> False\n",
            "<keras.layers.embeddings.Embedding object at 0x7f27b0111310> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f279dfe1150> True\n",
            "<keras.layers.wrappers.Bidirectional object at 0x7f27b4494890> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f279deb4ad0> True\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f279dfa9e50> True\n",
            "<keras.engine.input_layer.InputLayer object at 0x7f27b4491390> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f27b6204dd0> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f282b231b10> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f279dcb89d0> True\n",
            "<keras.layers.core.dropout.Dropout object at 0x7f279dcbe650> True\n",
            "<keras.layers.merge.Concatenate object at 0x7f279dda6350> True\n",
            "<keras.layers.core.dense.Dense object at 0x7f279dcd6b10> True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUCaJPKY9o_"
      },
      "source": [
        "Now our model is constructed, let's compile it.\n",
        "\n",
        "Here we'll use `label_smoothing`. Label smoothing helps to regularize our model (prevent overfitting) by making sure it doesn't get too focused on applying one particular label to a sample.\n",
        "\n",
        "For example, instead of having an output prediction of: \n",
        "* `[0.0, 0.0, 1.0, 0.0, 0.0]` for a sample (the model is very confident the right label is index 2).\n",
        "\n",
        "It's predictions will get smoothed to be something like:\n",
        "* `[0.01, 0.01, 0.096, 0.01, 0.01]` giving a small activation to each of the other labels, in turn, hopefully improving generalization.\n",
        "\n",
        "> ðŸ“– **Resource:** For more on label smoothing, see the great blog post by PyImageSearch, [*Label smoothing with Keras, TensorFlow, and Deep Learning*](https://www.pyimagesearch.com/2019/12/30/label-smoothing-with-keras-tensorflow-and-deep-learning/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwYd_dWPS8EB"
      },
      "source": [
        "# Compile token, char, positional embedding model\n",
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrXEGlcUZXAE"
      },
      "source": [
        "### Create tribrid embedding datasets and fit tribrid model\n",
        "\n",
        "This time the model requires four feature inputs:\n",
        "1. Train line numbers one-hot tensor (`train_line_numbers_one_hot`)\n",
        "2. Train total lines one-hot tensor (`train_total_lines_one_hot`)\n",
        "3. Token-level sequences tensor (`train_sentences`)\n",
        "4. Char-level sequences tensor (`train_chars`)\n",
        "\n",
        "We can pass these as tuples to our `tf.data.Dataset.from_tensor_slices()` method to create appropriately shaped and batched `PrefetchedDataset`'s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FDNHSIRyEE2",
        "outputId": "e1e81063-2e11-4be9-e095-d889ac1c9d90"
      },
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
        "                                                                train_total_lines_one_hot, # total lines\n",
        "                                                                train_sentences, # train tokens\n",
        "                                                                train_chars)) # train chars\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>,\n",
              " <PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiAjolB7yLxw",
        "outputId": "bf42574a-7312-478a-cdb4-847fceb8abe5"
      },
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 74s 123ms/step - loss: 1.0953 - accuracy: 0.7235 - val_loss: 0.9907 - val_accuracy: 0.7989\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 67s 120ms/step - loss: 0.9697 - accuracy: 0.8139 - val_loss: 0.9530 - val_accuracy: 0.8228\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 68s 120ms/step - loss: 0.9525 - accuracy: 0.8203 - val_loss: 0.9431 - val_accuracy: 0.8278\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6AtA9ffcC8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968c6e2c-af5a-40d3-acbf-d97e18f92ec4"
      },
      "source": [
        "# Make predictions with token-char-positional hybrid model\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 52s 54ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49613723, 0.1134618 , 0.01122889, 0.36125553, 0.01791657],\n",
              "       [0.5290977 , 0.11394692, 0.04049383, 0.30739197, 0.00906956],\n",
              "       [0.29102477, 0.11230903, 0.16304958, 0.3637461 , 0.06987049],\n",
              "       ...,\n",
              "       [0.03244559, 0.10651176, 0.04098266, 0.03012898, 0.78993106],\n",
              "       [0.02871831, 0.27374703, 0.07636031, 0.027854  , 0.59332037],\n",
              "       [0.22158003, 0.6025588 , 0.08805326, 0.03980987, 0.047998  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7x2LKrFc6CN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033d56ad-83da-4266-a027-28a7e1b10f97"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dogdVk02dO62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d06cd609-18f5-406f-d56f-fb2c64553178"
      },
      "source": [
        "# Calculate results of token-char-positional hybrid model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 83.14245994968886,\n",
              " 'f1': 0.8304876122242683,\n",
              " 'precision': 0.8311776956973732,\n",
              " 'recall': 0.8314245994968886}"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yranVE5soBdf"
      },
      "source": [
        "## Compare model results \n",
        "\n",
        "Now it's time to compare each model's performance against each other.\n",
        "\n",
        "We'll also be able to compare our model's to the [*PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper.\n",
        "\n",
        "Since all of our model results are in dictionaries, let's combine them into a pandas DataFrame to visualize them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJtoRSYGb2VP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "20c6412f-02c5-498c-a69c-eb3c007f4786"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"custom_token_embed_conv1d\": model_1_results,\n",
        "                                  \"pretrained_token_embed\": model_2_results,\n",
        "                                  \"custom_char_embed_conv1d\": model_3_results,\n",
        "                                  \"hybrid_char_token_embed\": model_4_results,\n",
        "                                  \"tribrid_pos_char_token_embed\": model_5_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-640493fb-24a8-49f2-9c25-0f12b1c1ea21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>72.183238</td>\n",
              "      <td>0.718647</td>\n",
              "      <td>0.721832</td>\n",
              "      <td>0.698925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>custom_token_embed_conv1d</th>\n",
              "      <td>78.286773</td>\n",
              "      <td>0.779379</td>\n",
              "      <td>0.782868</td>\n",
              "      <td>0.780499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pretrained_token_embed</th>\n",
              "      <td>71.382232</td>\n",
              "      <td>0.714244</td>\n",
              "      <td>0.713822</td>\n",
              "      <td>0.710743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>custom_char_embed_conv1d</th>\n",
              "      <td>65.272077</td>\n",
              "      <td>0.643539</td>\n",
              "      <td>0.652721</td>\n",
              "      <td>0.640687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hybrid_char_token_embed</th>\n",
              "      <td>73.202701</td>\n",
              "      <td>0.732531</td>\n",
              "      <td>0.732027</td>\n",
              "      <td>0.729246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tribrid_pos_char_token_embed</th>\n",
              "      <td>83.142460</td>\n",
              "      <td>0.831178</td>\n",
              "      <td>0.831425</td>\n",
              "      <td>0.830488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-640493fb-24a8-49f2-9c25-0f12b1c1ea21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-640493fb-24a8-49f2-9c25-0f12b1c1ea21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-640493fb-24a8-49f2-9c25-0f12b1c1ea21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                               accuracy  precision    recall        f1\n",
              "baseline                      72.183238   0.718647  0.721832  0.698925\n",
              "custom_token_embed_conv1d     78.286773   0.779379  0.782868  0.780499\n",
              "pretrained_token_embed        71.382232   0.714244  0.713822  0.710743\n",
              "custom_char_embed_conv1d      65.272077   0.643539  0.652721  0.640687\n",
              "hybrid_char_token_embed       73.202701   0.732531  0.732027  0.729246\n",
              "tribrid_pos_char_token_embed  83.142460   0.831178  0.831425  0.830488"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G--0tQkb5tq"
      },
      "source": [
        "# Reduce the accuracy to same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHtN7qJ3cAA3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "81a1f46a-7503-407c-cc62-e9b24561ced7"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI36lZHpcE53"
      },
      "source": [
        "Since the [*PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper compares their tested model's F1-scores on the test dataset, let's take at our model's F1-scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtDMFKsCcD1j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "664b3637-98d4-4757-8b7f-6e109344aec2"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7));"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEoLsCNbwNRA"
      },
      "source": [
        "Based on F1-scores, it looks like our tribrid embedding model performs the best by a fair margin.\n",
        "\n",
        "Though, in comparison to the results reported in Table 3 of the [*PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, our model's F1-score is still underperforming (the authors model achieves an F1-score of 90.0 on the 20k RCT dataset versus our F1-score of ~82.6).\n",
        "\n",
        "There are some things to note about this difference:\n",
        "* Our models (with an exception for the baseline) have been trained on ~18,000 (10% of batches) samples of sequences and labels rather than the full ~180,000 in the 20k RCT dataset.\n",
        "* Our model's prediction performance levels have been evaluated on the validation dataset not the test dataset (we'll evaluate our best model on the test dataset shortly)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk5rMP0rarWG"
      },
      "source": [
        "## Save and load best performing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRalPoXEi0Es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f3a0fae-5887-4e5e-a302-44bd600b6cbc"
      },
      "source": [
        "# Save best performing model to SavedModel format (default)\n",
        "model_5.save(\"skimit_tribrid_model\") # model will be saved to path specified by string"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: skimit_tribrid_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: skimit_tribrid_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f279de6d450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f279ddf7050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uq0MFPiaoUb"
      },
      "source": [
        "## Evaluate model on test dataset\n",
        "\n",
        "To make our model's performance more comparable with the results reported in Table 3 of the [*PubMed 200k RCT:\n",
        "a Dataset for Sequential Sentence Classification in Medical Abstracts*](https://arxiv.org/pdf/1710.06071.pdf) paper, let's make predictions on the test dataset and evaluate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkFb3giT2FYW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c264cd-cee3-4faa-82ae-5ca880ff520d"
      },
      "source": [
        "# Create test dataset batch and prefetched\n",
        "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
        "                                                               test_total_lines_one_hot,\n",
        "                                                               test_sentences,\n",
        "                                                               test_chars))\n",
        "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
        "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Check shapes\n",
        "test_pos_char_token_dataset"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (((None, 15), (None, 20), (None,), (None,)), (None, 5)), types: ((tf.float32, tf.float32, tf.string, tf.string), tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpoQj-PexFf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99468d66-a4f4-4f09-d6f7-5d6598a4617e"
      },
      "source": [
        "# Make predictions on the test dataset\n",
        "test_pred_probs = model_5.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 51s 54ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([3, 0, 2, 2, 4, 4, 4, 1, 4, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avvjksEqxe_0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f143eec-e8ed-4404-e950-75f84a60a1f7"
      },
      "source": [
        "# Evaluate loaded model test predictions\n",
        "loaded_model_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds)\n",
        "loaded_model_test_results"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 82.62485481997676,\n",
              " 'f1': 0.8252188273086626,\n",
              " 'precision': 0.8253201068639433,\n",
              " 'recall': 0.8262485481997677}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eupgOniJ3rLr"
      },
      "source": [
        "It seems our best model (so far) still has some ways to go to match the performance of the results in the paper (their model gets 90.0 F1-score on the test dataset, where as ours gets ~82.1 F1-score).\n",
        "\n",
        "However, as we discussed before our model has only been trained on 20,000 out of the total ~180,000 sequences in the RCT 20k dataset. We also haven't fine-tuned our pretrained embeddings (the paper fine-tunes GloVe embeddings). So there's a couple of extensions we could try to improve our results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8orhq8dPAuW"
      },
      "source": [
        "## Find most wrong\n",
        "\n",
        "The most wrong predictions are samples where the model has made a prediction with a high probability but has gotten it wrong (the model's prediction disagreess with the ground truth label).\n",
        "\n",
        "Looking at the most wrong predictions can give us valuable information on how to improve further models or fix the labels in our data.\n",
        "\n",
        "First we'll convert all of our integer-based test predictions into their string-based class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yI34yymyycT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d01db8-3fc2-49d4-f5c4-d7d6d56e9949"
      },
      "source": [
        "%%time\n",
        "# Get list of class names of test predictions\n",
        "test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n",
        "test_pred_classes"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.8 s, sys: 1.35 s, total: 17.1 s\n",
            "Wall time: 14.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B41eg6O6DbQ"
      },
      "source": [
        "Now we'll enrich our test DataFame with a few values:\n",
        "* A `\"prediction\"` (string) column containing our model's prediction for a given sample.\n",
        "* A `\"pred_prob\"` (float) column containing the model's maximum prediction probabiliy for a given sample.\n",
        "* A `\"correct\"` (bool) column to indicate whether or not the model's prediction matches the sample's target label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au11pLUEPCaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "24afd026-86ca-4387-e6c8-723f74f5668e"
      },
      "source": [
        "# Create prediction-enriched test dataframe\n",
        "test_df[\"prediction\"] = test_pred_classes # create column with test prediction class names\n",
        "test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # get the maximum prediction probability\n",
        "test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # create binary column for whether the prediction is right or not\n",
        "test_df.head(20)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9d2f09bd-3e64-42a1-9ac9-2f6119228366\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "      <th>prediction</th>\n",
              "      <th>pred_prob</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>this study analyzed liver function abnormaliti...</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>0.463727</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>a post hoc analysis was conducted with the use...</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>0.370104</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>liver function tests ( lfts ) were measured at...</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.807607</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>survival analyses were used to assess the asso...</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.620032</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the percentage of patients with abnormal lfts ...</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.695288</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>when mean hemodynamic profiles were compared i...</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.879299</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>multivariable analyses revealed that patients ...</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.606484</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>abnormal lfts are common in the adhf populatio...</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>0.503163</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>elevated meld-xi scores are associated with po...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.452665</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>minimally invasive endovascular aneurysm repai...</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>0.547764</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>the aim of this study was to analyse the cost-...</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>0.508109</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>resource use was determined from the amsterdam...</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.569382</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>the analysis was performed from a provider per...</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.861639</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>all costs were calculated as if all patients h...</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.560848</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>a total of @ patients were randomized .</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.716546</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the @-day mortality rate was @ per cent after ...</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.682002</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>at @months , the total mortality rate for evar...</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.902429</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the mean cost difference between evar and or w...</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.865654</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>the incremental cost-effectiveness ratio per p...</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.805569</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>there was no significant difference in quality...</td>\n",
              "      <td>10</td>\n",
              "      <td>12</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.763040</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d2f09bd-3e64-42a1-9ac9-2f6119228366')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d2f09bd-3e64-42a1-9ac9-2f6119228366 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d2f09bd-3e64-42a1-9ac9-2f6119228366');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         target  ... correct\n",
              "0    BACKGROUND  ...   False\n",
              "1       RESULTS  ...   False\n",
              "2       RESULTS  ...   False\n",
              "3       RESULTS  ...   False\n",
              "4       RESULTS  ...    True\n",
              "5       RESULTS  ...    True\n",
              "6       RESULTS  ...    True\n",
              "7   CONCLUSIONS  ...    True\n",
              "8   CONCLUSIONS  ...   False\n",
              "9    BACKGROUND  ...    True\n",
              "10   BACKGROUND  ...   False\n",
              "11      METHODS  ...    True\n",
              "12      METHODS  ...    True\n",
              "13      METHODS  ...    True\n",
              "14      RESULTS  ...    True\n",
              "15      RESULTS  ...    True\n",
              "16      RESULTS  ...    True\n",
              "17      RESULTS  ...    True\n",
              "18      RESULTS  ...    True\n",
              "19      RESULTS  ...    True\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDUOsuKJ6IQH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "e1ee5276-8846-4036-c054-2c632e172d3b"
      },
      "source": [
        "# Find top 100 most wrong samples (note: 100 is an abitrary number, you could go through all of them if you wanted)\n",
        "top_100_wrong = test_df[test_df[\"correct\"] == False].sort_values(\"pred_prob\", ascending=False)[:100]\n",
        "top_100_wrong"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e7ed3a7f-3eea-4fef-9f23-66d0da28c0a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "      <th>prediction</th>\n",
              "      <th>pred_prob</th>\n",
              "      <th>correct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13874</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>symptom outcomes will be assessed and estimate...</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.950875</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1827</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>nct@ ( clinicaltrials.gov ) .</td>\n",
              "      <td>18</td>\n",
              "      <td>18</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>0.938208</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8545</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pretest-posttest .</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>0.936310</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16347</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>to evaluate the effects of the lactic acid bac...</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>0.931017</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16633</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>clinicaltrials.gov identifier : nct@ .</td>\n",
              "      <td>19</td>\n",
              "      <td>19</td>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>0.930502</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>only @ students ( @ % ) agreed they were ready...</td>\n",
              "      <td>5</td>\n",
              "      <td>13</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.841581</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12456</th>\n",
              "      <td>RESULTS</td>\n",
              "      <td>icd patients were randomized @:@ to automatic ...</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>METHODS</td>\n",
              "      <td>0.841432</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7968</th>\n",
              "      <td>BACKGROUND</td>\n",
              "      <td>dpbrn hygienists internet quality improvement ...</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>0.839596</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19223</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>of the @ dogs receiving placebo , @ ( @ % ) vo...</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.839320</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2219</th>\n",
              "      <td>CONCLUSIONS</td>\n",
              "      <td>among men and women with moderately elevated b...</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>RESULTS</td>\n",
              "      <td>0.838959</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7ed3a7f-3eea-4fef-9f23-66d0da28c0a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7ed3a7f-3eea-4fef-9f23-66d0da28c0a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7ed3a7f-3eea-4fef-9f23-66d0da28c0a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            target  ... correct\n",
              "13874  CONCLUSIONS  ...   False\n",
              "1827   CONCLUSIONS  ...   False\n",
              "8545       METHODS  ...   False\n",
              "16347   BACKGROUND  ...   False\n",
              "16633  CONCLUSIONS  ...   False\n",
              "...            ...  ...     ...\n",
              "604        RESULTS  ...   False\n",
              "12456      RESULTS  ...   False\n",
              "7968    BACKGROUND  ...   False\n",
              "19223      METHODS  ...   False\n",
              "2219   CONCLUSIONS  ...   False\n",
              "\n",
              "[100 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysddyYy717HJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df90778-4e58-44c4-9f40-4b68dd30a9c9"
      },
      "source": [
        "# Investigate top wrong preds\n",
        "for row in top_100_wrong[0:10].itertuples(): # adjust indexes to view different samples\n",
        "  _, target, text, line_number, total_lines, prediction, pred_prob, _ = row\n",
        "  print(f\"Target: {target}, Pred: {prediction}, Prob: {pred_prob}, Line number: {line_number}, Total lines: {total_lines}\\n\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: CONCLUSIONS, Pred: METHODS, Prob: 0.9508748054504395, Line number: 4, Total lines: 6\n",
            "\n",
            "Text:\n",
            "symptom outcomes will be assessed and estimates of cost-effectiveness made .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: CONCLUSIONS, Pred: BACKGROUND, Prob: 0.9382083415985107, Line number: 18, Total lines: 18\n",
            "\n",
            "Text:\n",
            "nct@ ( clinicaltrials.gov ) .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: METHODS, Pred: BACKGROUND, Prob: 0.9363095760345459, Line number: 1, Total lines: 11\n",
            "\n",
            "Text:\n",
            "pretest-posttest .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: BACKGROUND, Pred: OBJECTIVE, Prob: 0.931017279624939, Line number: 0, Total lines: 12\n",
            "\n",
            "Text:\n",
            "to evaluate the effects of the lactic acid bacterium lactobacillus salivarius on caries risk factors .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: CONCLUSIONS, Pred: BACKGROUND, Prob: 0.9305015206336975, Line number: 19, Total lines: 19\n",
            "\n",
            "Text:\n",
            "clinicaltrials.gov identifier : nct@ .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: CONCLUSIONS, Pred: BACKGROUND, Prob: 0.9233525395393372, Line number: 13, Total lines: 13\n",
            "\n",
            "Text:\n",
            "( clinicaltrials.gov : nct@ ) .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: METHODS, Pred: RESULTS, Prob: 0.9221022725105286, Line number: 6, Total lines: 9\n",
            "\n",
            "Text:\n",
            "-@ % vs. fish : -@ % vs. fish + s : -@ % ; p < @ ) but there were no significant differences between groups .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: RESULTS, Pred: METHODS, Prob: 0.9188870191574097, Line number: 4, Total lines: 13\n",
            "\n",
            "Text:\n",
            "the primary endpoint is the cumulative three-year hiv incidence .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: CONCLUSIONS, Pred: BACKGROUND, Prob: 0.9147139191627502, Line number: 15, Total lines: 15\n",
            "\n",
            "Text:\n",
            "unique identifier : nct@ .\n",
            "\n",
            "-----\n",
            "\n",
            "Target: CONCLUSIONS, Pred: BACKGROUND, Prob: 0.9125070571899414, Line number: 15, Total lines: 15\n",
            "\n",
            "Text:\n",
            "-lsb- netherlands trial register ( http://www.trialregister.nl/trialreg/index.asp ) , nr @ , date of registration @ december @ . -rsb-\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model on the whole 20k dataset"
      ],
      "metadata": {
        "id": "Nyf0NHFMPEgq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### creating callbacks"
      ],
      "metadata": {
        "id": "DrkIYOtBPgMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 3 epochs\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", # watch the val loss metric\n",
        "                               patience=3) # if val loss decreases for 3 epochs in a row, stop training\n",
        "\n",
        "# Create ModelCheckpoint callback to save best model during fine-tuning\n",
        "checkpoint_path = \"checkpoints/\"\n",
        "model_checkpoint = ModelCheckpoint(checkpoint_path,\n",
        "                                   save_best_only=True,\n",
        "                                   monitor=\"val_loss\")"
      ],
      "metadata": {
        "id": "Bi-qjxYMPmyD"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "\n",
        "# 1. Token inputs\n",
        "token_inputs = layers.Input(shape=[], dtype=\"string\", name=\"token_inputs\")\n",
        "token_embeddings = tf_hub_embedding_layer(token_inputs)\n",
        "token_outputs = layers.Dense(128, activation=\"relu\")(token_embeddings)\n",
        "token_model = tf.keras.Model(inputs=token_inputs,\n",
        "                             outputs=token_outputs)\n",
        "\n",
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(32))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)\n",
        "\n",
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(32, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)\n",
        "\n",
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(32, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)\n",
        "\n",
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output, \n",
        "                                                                              char_model.output])\n",
        "z = layers.Dense(256, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5_20k = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input, \n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)"
      ],
      "metadata": {
        "id": "iUyGWPiFCS5N"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compiling and trainig"
      ],
      "metadata": {
        "id": "lr7QHCtyP28z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile token, char, positional embedding model\n",
        "model_5_20k.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ifVtUMoaP7Er"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5_20k = model_5_20k.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(len(train_pos_char_token_dataset)),\n",
        "                              epochs=100,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(len(val_pos_char_token_dataset)),\n",
        "                              callbacks=[model_checkpoint, early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvf8ft4QPWAa",
        "outputId": "071d1fd3-4faa-4629-ac1a-c30f296958f5"
      },
      "execution_count": 117,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "5627/5627 [==============================] - ETA: 0s - loss: 0.9538 - accuracy: 0.8232"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f27991011d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2796c0d790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5627/5627 [==============================] - 700s 124ms/step - loss: 0.9538 - accuracy: 0.8232 - val_loss: 0.9091 - val_accuracy: 0.8463\n",
            "Epoch 2/100\n",
            "5627/5627 [==============================] - ETA: 0s - loss: 0.9087 - accuracy: 0.8548"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f27991011d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2796c0d790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5627/5627 [==============================] - 688s 122ms/step - loss: 0.9087 - accuracy: 0.8548 - val_loss: 0.8980 - val_accuracy: 0.8535\n",
            "Epoch 3/100\n",
            "5627/5627 [==============================] - ETA: 0s - loss: 0.8964 - accuracy: 0.8638"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f27991011d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2796c0d790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5627/5627 [==============================] - 696s 124ms/step - loss: 0.8964 - accuracy: 0.8638 - val_loss: 0.8956 - val_accuracy: 0.8561\n",
            "Epoch 4/100\n",
            "5627/5627 [==============================] - ETA: 0s - loss: 0.8880 - accuracy: 0.8703"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: checkpoints/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f27991011d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2796c0d790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5627/5627 [==============================] - 680s 121ms/step - loss: 0.8880 - accuracy: 0.8703 - val_loss: 0.8946 - val_accuracy: 0.8571\n",
            "Epoch 5/100\n",
            "5627/5627 [==============================] - 655s 116ms/step - loss: 0.8810 - accuracy: 0.8755 - val_loss: 0.8972 - val_accuracy: 0.8561\n",
            "Epoch 6/100\n",
            "5627/5627 [==============================] - 667s 119ms/step - loss: 0.8751 - accuracy: 0.8794 - val_loss: 0.8960 - val_accuracy: 0.8552\n",
            "Epoch 7/100\n",
            "5627/5627 [==============================] - 664s 118ms/step - loss: 0.8710 - accuracy: 0.8827 - val_loss: 0.8981 - val_accuracy: 0.8557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save best performing model to SavedModel format (default)\n",
        "model_5_20k.save(\"skimit_20k_model\") # model will be saved to path specified by string\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# copying saved model from Google Colab to Drive\n",
        "!cp skimit_20k_model -r /content/drive/MyDrive/skim_lit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mYaxd4Opryr",
        "outputId": "c4a03ca3-4437-416e-ee3f-46dd3a0bb56b"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_7_layer_call_fn, lstm_cell_7_layer_call_and_return_conditional_losses, lstm_cell_8_layer_call_fn, lstm_cell_8_layer_call_and_return_conditional_losses, lstm_cell_7_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: skimit_20k_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: skimit_20k_model/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f27991011d0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f2796c0d790> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with token-char-positional hybrid model\n",
        "model_5_20k_pred_probs = model_5_20k.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_20k_pred_probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPsiWOPGqMHC",
        "outputId": "d72b7252-876c-4d06-f0f1-2c6e210cd098"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 47s 50ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60705054, 0.07953526, 0.02647945, 0.26008758, 0.02684727],\n",
              "       [0.6285315 , 0.11062677, 0.04210354, 0.20182247, 0.01691562],\n",
              "       [0.27947485, 0.07527035, 0.01276496, 0.60218495, 0.03030481],\n",
              "       ...,\n",
              "       [0.02488911, 0.07758875, 0.01879515, 0.03136536, 0.8473616 ],\n",
              "       [0.02506821, 0.18991305, 0.03834326, 0.03060083, 0.71607465],\n",
              "       [0.04778387, 0.8930656 , 0.02318021, 0.022383  , 0.0135874 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_20k_preds = tf.argmax(model_5_20k_pred_probs, axis=1)\n",
        "model_5_20k_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZugCzJxBgfd",
        "outputId": "c2309dd5-fc2e-4d7a-94e3-08c3c23fd5db"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 4, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results of token-char-positional hybrid model on val_data\n",
        "model_5_20k_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_20k_preds)\n",
        "model_5_20k_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO6eZiItqSm4",
        "outputId": "998eb785-82d6-431f-cbd9-cb6eafe796f8"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.5719581623196,\n",
              " 'f1': 0.8530298869923539,\n",
              " 'precision': 0.8576694186881618,\n",
              " 'recall': 0.8557195816231961}"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f30a77c-c69e-457b-e46e-11ab26510bc0",
        "id": "p6TYibqgDAG_"
      },
      "source": [
        "# Make predictions on the test dataset\n",
        "test_pred_20k_probs = model_5_20k.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds_20k = tf.argmax(test_pred_20k_probs, axis=1)\n",
        "test_preds_20k[:10]"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "942/942 [==============================] - 47s 50ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([3, 2, 2, 2, 4, 4, 4, 1, 1, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate loaded model test predictions\n",
        "model_5_20k_test_results = calculate_results(y_true=test_labels_encoded,\n",
        "                                              y_pred=test_preds_20k)\n",
        "model_5_20k_test_results"
      ],
      "metadata": {
        "id": "6pEBSLt7DtQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92af3ca2-b2a6-4270-c18f-f5b8801c6ef9"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 84.94441679110669,\n",
              " 'f1': 0.8464598706510257,\n",
              " 'precision': 0.8502937550505183,\n",
              " 'recall': 0.8494441679110669}"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_5_20k_test_results['f1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Gvv8vfqie1",
        "outputId": "8ba493c7-e630-49a0-9a6f-ee24201af644"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8464598706510257"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make example predictions\n"
      ],
      "metadata": {
        "id": "LE3qukFp1Haf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pfz_b-Tmapdz"
      },
      "source": [
        "Okay, we've made some predictions on the test dataset, now's time to really test our model out.\n",
        "\n",
        "To do so, we're going to get some data and see how our model performs.\n",
        "\n",
        "In other words, were going to find an RCT abstract from PubMed, preprocess the text so it works with our model, then pass each sequence in the abstract through our model to see what label it predicts.\n",
        "\n",
        "For an appropriate sample, we'll need to search PubMed for RCT's (randomized controlled trials) without abstracts which have been split up.\n",
        "\n",
        "Going through various PubMed studies, I managed to find the following unstructured abstract from [*RCT of a manualized social treatment for high-functioning autism spectrum disorders*](https://pubmed.ncbi.nlm.nih.gov/20232240/):\n",
        "\n",
        "> This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n",
        "\n",
        "Looking at the large chunk of text can seem quite intimidating. Now imagine you're a medical researcher trying to skim through the literature to find a study relevant to your work.\n",
        "\n",
        "Sounds like quite the challenge right?\n",
        "\n",
        "Enter Skimit!\n",
        "\n",
        "Let's see what our best model so far (`model_5_200k`) makes of the above abstract.\n",
        "\n",
        "As the above abstract hasn't been formatted in the same structure as the data our model has been trained on. Therefore, before we can make a prediction on it, we need to preprocess it just as we have our other sequences.\n",
        "\n",
        "More specifically, for each abstract, we'll need to:\n",
        "\n",
        "1. Split it into sentences (lines).\n",
        "2. Split it into characters.\n",
        "3. Find the number of each line.\n",
        "4. Find the total number of lines.\n",
        "\n",
        "Starting with number 1, there are a couple of ways to split our abstracts into actual sentences. A simple one would be to use Python's in-built `split()` string method, splitting the abstract wherever a fullstop appears. However, can you imagine where this might go wrong? \n",
        "\n",
        "Another more advanced option would be to leverage [spaCy's](https://spacy.io/) (a very powerful NLP library) [`sentencizer`](https://spacy.io/usage/linguistic-features#sbd) class. Which is an easy to use sentence splitter based on spaCy's English language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qKFXysU9Y1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adac1548-501a-4024-c2ee-bce1ad68d440"
      },
      "source": [
        "# Download and open example abstracts (copy and pasted from PubMed)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "import json\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-23 17:44:04--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6737 (6.6K) [text/plain]\n",
            "Saving to: â€˜skimlit_example_abstracts.jsonâ€™\n",
            "\n",
            "skimlit_example_abs 100%[===================>]   6.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-01-23 17:44:05 (50.9 MB/s) - â€˜skimlit_example_abstracts.jsonâ€™ saved [6737/6737]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'abstract': 'This RCT examined the efficacy of a manualized social intervention for children with HFASDs. Participants were randomly assigned to treatment or wait-list conditions. Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language. A response-cost program was applied to reduce problem behaviors and foster skills acquisition. Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures). Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents. High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity. Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.',\n",
              "  'details': 'RCT of a manualized social treatment for high-functioning autism spectrum disorders',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/20232240/'},\n",
              " {'abstract': \"Postpartum depression (PPD) is the most prevalent mood disorder associated with childbirth. No single cause of PPD has been identified, however the increased risk of nutritional deficiencies incurred through the high nutritional requirements of pregnancy may play a role in the pathology of depressive symptoms. Three nutritional interventions have drawn particular interest as possible non-invasive and cost-effective prevention and/or treatment strategies for PPD; omega-3 (n-3) long chain polyunsaturated fatty acids (LCPUFA), vitamin D and overall diet. We searched for meta-analyses of randomised controlled trials (RCT's) of nutritional interventions during the perinatal period with PPD as an outcome, and checked for any trials published subsequently to the meta-analyses. Fish oil: Eleven RCT's of prenatal fish oil supplementation RCT's show null and positive effects on PPD symptoms. Vitamin D: no relevant RCT's were identified, however seven observational studies of maternal vitamin D levels with PPD outcomes showed inconsistent associations. Diet: Two Australian RCT's with dietary advice interventions in pregnancy had a positive and null result on PPD. With the exception of fish oil, few RCT's with nutritional interventions during pregnancy assess PPD. Further research is needed to determine whether nutritional intervention strategies during pregnancy can protect against symptoms of PPD. Given the prevalence of PPD and ease of administering PPD measures, we recommend future prenatal nutritional RCT's include PPD as an outcome.\",\n",
              "  'details': 'Formatting removed (can be used to compare model to actual example)',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/28012571/'},\n",
              " {'abstract': 'Mental illness, including depression, anxiety and bipolar disorder, accounts for a significant proportion of global disability and poses a substantial social, economic and heath burden. Treatment is presently dominated by pharmacotherapy, such as antidepressants, and psychotherapy, such as cognitive behavioural therapy; however, such treatments avert less than half of the disease burden, suggesting that additional strategies are needed to prevent and treat mental disorders. There are now consistent mechanistic, observational and interventional data to suggest diet quality may be a modifiable risk factor for mental illness. This review provides an overview of the nutritional psychiatry field. It includes a discussion of the neurobiological mechanisms likely modulated by diet, the use of dietary and nutraceutical interventions in mental disorders, and recommendations for further research. Potential biological pathways related to mental disorders include inflammation, oxidative stress, the gut microbiome, epigenetic modifications and neuroplasticity. Consistent epidemiological evidence, particularly for depression, suggests an association between measures of diet quality and mental health, across multiple populations and age groups; these do not appear to be explained by other demographic, lifestyle factors or reverse causality. Our recently published intervention trial provides preliminary clinical evidence that dietary interventions in clinically diagnosed populations are feasible and can provide significant clinical benefit. Furthermore, nutraceuticals including n-3 fatty acids, folate, S-adenosylmethionine, N-acetyl cysteine and probiotics, among others, are promising avenues for future research. Continued research is now required to investigate the efficacy of intervention studies in large cohorts and within clinically relevant populations, particularly in patients with schizophrenia, bipolar and anxiety disorders.',\n",
              "  'details': 'Effect of nutrition on mental health',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/28942748/'},\n",
              " {'abstract': \"Hepatitis C virus (HCV) and alcoholic liver disease (ALD), either alone or in combination, count for more than two thirds of all liver diseases in the Western world. There is no safe level of drinking in HCV-infected patients and the most effective goal for these patients is total abstinence. Baclofen, a GABA(B) receptor agonist, represents a promising pharmacotherapy for alcohol dependence (AD). Previously, we performed a randomized clinical trial (RCT), which demonstrated the safety and efficacy of baclofen in patients affected by AD and cirrhosis. The goal of this post-hoc analysis was to explore baclofen's effect in a subgroup of alcohol-dependent HCV-infected cirrhotic patients. Any patient with HCV infection was selected for this analysis. Among the 84 subjects randomized in the main trial, 24 alcohol-dependent cirrhotic patients had a HCV infection; 12 received baclofen 10mg t.i.d. and 12 received placebo for 12-weeks. With respect to the placebo group (3/12, 25.0%), a significantly higher number of patients who achieved and maintained total alcohol abstinence was found in the baclofen group (10/12, 83.3%; p=0.0123). Furthermore, in the baclofen group, compared to placebo, there was a significantly higher increase in albumin values from baseline (p=0.0132) and a trend toward a significant reduction in INR levels from baseline (p=0.0716). In conclusion, baclofen was safe and significantly more effective than placebo in promoting alcohol abstinence, and improving some Liver Function Tests (LFTs) (i.e. albumin, INR) in alcohol-dependent HCV-infected cirrhotic patients. Baclofen may represent a clinically relevant alcohol pharmacotherapy for these patients.\",\n",
              "  'details': 'Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection',\n",
              "  'source': 'https://pubmed.ncbi.nlm.nih.gov/22244707/'}]"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1cIAS1Z6r_l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "943a08e9-82fc-4e2f-d9d5-4cc9eb064424"
      },
      "source": [
        "# See what our example abstracts look like\n",
        "abstracts = pd.DataFrame(example_abstracts)\n",
        "abstracts"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6ad0c949-69b0-4ef6-a17b-d6cc6c13075f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abstract</th>\n",
              "      <th>source</th>\n",
              "      <th>details</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This RCT examined the efficacy of a manualized...</td>\n",
              "      <td>https://pubmed.ncbi.nlm.nih.gov/20232240/</td>\n",
              "      <td>RCT of a manualized social treatment for high-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Postpartum depression (PPD) is the most preval...</td>\n",
              "      <td>https://pubmed.ncbi.nlm.nih.gov/28012571/</td>\n",
              "      <td>Formatting removed (can be used to compare mod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mental illness, including depression, anxiety ...</td>\n",
              "      <td>https://pubmed.ncbi.nlm.nih.gov/28942748/</td>\n",
              "      <td>Effect of nutrition on mental health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hepatitis C virus (HCV) and alcoholic liver di...</td>\n",
              "      <td>https://pubmed.ncbi.nlm.nih.gov/22244707/</td>\n",
              "      <td>Baclofen promotes alcohol abstinence in alcoho...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ad0c949-69b0-4ef6-a17b-d6cc6c13075f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ad0c949-69b0-4ef6-a17b-d6cc6c13075f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ad0c949-69b0-4ef6-a17b-d6cc6c13075f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            abstract  ...                                            details\n",
              "0  This RCT examined the efficacy of a manualized...  ...  RCT of a manualized social treatment for high-...\n",
              "1  Postpartum depression (PPD) is the most preval...  ...  Formatting removed (can be used to compare mod...\n",
              "2  Mental illness, including depression, anxiety ...  ...               Effect of nutrition on mental health\n",
              "3  Hepatitis C virus (HCV) and alcoholic liver di...  ...  Baclofen promotes alcohol abstinence in alcoho...\n",
              "\n",
              "[4 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnZWtDki9uxc"
      },
      "source": [
        "Now we've downloaded some example abstracts, let's see how one of them goes with our trained model.\n",
        "\n",
        "First, we'll need to parse it using spaCy to turn it from a big chunk of text into sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gwVNdLQHpQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1739142a-79be-4e8a-acc6-8e8b78196679"
      },
      "source": [
        "# Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd \n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "sentencizer = nlp.create_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "nlp.add_pipe(sentencizer) # add sentence splitting pipeline object to sentence parser\n",
        "doc = nlp(example_abstracts[0][\"abstract\"]) # create \"doc\" of parsed sequences, change index for a different abstract\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type (not spaCy token type)\n",
        "abstract_lines"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This RCT examined the efficacy of a manualized social intervention for children with HFASDs.',\n",
              " 'Participants were randomly assigned to treatment or wait-list conditions.',\n",
              " 'Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.',\n",
              " 'A response-cost program was applied to reduce problem behaviors and foster skills acquisition.',\n",
              " 'Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).',\n",
              " 'Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.',\n",
              " 'High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.',\n",
              " 'Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.']"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiCg-H4G16Gx"
      },
      "source": [
        "It looks like spaCy has split the sentences in the abstract correctly. However, it should be noted, there may be more complex abstracts which don't get split perfectly into separate sentences (such as the example in [*Baclofen promotes alcohol abstinence in alcohol dependent cirrhotic patients with hepatitis C virus (HCV) infection*](https://pubmed.ncbi.nlm.nih.gov/22244707/)), in this case, more custom splitting techniques would have to be investigated.\n",
        "\n",
        "Now our abstract has been split into sentences, how about we write some code to count line numbers as well as total lines.\n",
        "\n",
        "To do so, we can leverage some of the functionality of our `preprocess_text_with_line_numbers()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_Hi0alJI4Xu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d59e4a56-c4c7-4835-cbab-0a0ad54ac000"
      },
      "source": [
        "# Get total number of lines\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Go through each line in abstract and create a list of dictionaries containing features for each line\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'text': 'This RCT examined the efficacy of a manualized social intervention for children with HFASDs.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 1,\n",
              "  'text': 'Participants were randomly assigned to treatment or wait-list conditions.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 2,\n",
              "  'text': 'Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 3,\n",
              "  'text': 'A response-cost program was applied to reduce problem behaviors and foster skills acquisition.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 4,\n",
              "  'text': 'Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 5,\n",
              "  'text': 'Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 6,\n",
              "  'text': 'High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.',\n",
              "  'total_lines': 7},\n",
              " {'line_number': 7,\n",
              "  'text': 'Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.',\n",
              "  'total_lines': 7}]"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17X7ez2r37Nw"
      },
      "source": [
        "Now we've got `\"line_number\"` and `\"total_lines\"` values, we can one-hot encode them with `tf.one_hot` just like we did with our training dataset (using the same values for the `depth` parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm0MYaAnBkbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78f8348b-0651-4e27-95f2-6c585ebf1816"
      },
      "source": [
        "# Get all line_number values from sample abstract\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15) \n",
        "test_abstract_line_numbers_one_hot"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 15), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wzbv3w6B3OU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5d9342-8c88-4bcb-a354-b50454583333"
      },
      "source": [
        "# Get all total_lines values from sample abstract\n",
        "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
        "test_abstract_total_lines_one_hot"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8, 20), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq-f17G440ur"
      },
      "source": [
        "We can also use our `split_chars()` function to split our abstract lines into characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOOPoG3cCA0F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238f3598-5130-4146-ad3f-0a67d8aee0fc"
      },
      "source": [
        "# Split abstract lines into characters\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['T h i s   R C T   e x a m i n e d   t h e   e f f i c a c y   o f   a   m a n u a l i z e d   s o c i a l   i n t e r v e n t i o n   f o r   c h i l d r e n   w i t h   H F A S D s .',\n",
              " 'P a r t i c i p a n t s   w e r e   r a n d o m l y   a s s i g n e d   t o   t r e a t m e n t   o r   w a i t - l i s t   c o n d i t i o n s .',\n",
              " 'T r e a t m e n t   i n c l u d e d   i n s t r u c t i o n   a n d   t h e r a p e u t i c   a c t i v i t i e s   t a r g e t i n g   s o c i a l   s k i l l s ,   f a c e - e m o t i o n   r e c o g n i t i o n ,   i n t e r e s t   e x p a n s i o n ,   a n d   i n t e r p r e t a t i o n   o f   n o n - l i t e r a l   l a n g u a g e .',\n",
              " 'A   r e s p o n s e - c o s t   p r o g r a m   w a s   a p p l i e d   t o   r e d u c e   p r o b l e m   b e h a v i o r s   a n d   f o s t e r   s k i l l s   a c q u i s i t i o n .',\n",
              " 'S i g n i f i c a n t   t r e a t m e n t   e f f e c t s   w e r e   f o u n d   f o r   f i v e   o f   s e v e n   p r i m a r y   o u t c o m e   m e a s u r e s   ( p a r e n t   r a t i n g s   a n d   d i r e c t   c h i l d   m e a s u r e s ) .',\n",
              " 'S e c o n d a r y   m e a s u r e s   b a s e d   o n   s t a f f   r a t i n g s   ( t r e a t m e n t   g r o u p   o n l y )   c o r r o b o r a t e d   g a i n s   r e p o r t e d   b y   p a r e n t s .',\n",
              " 'H i g h   l e v e l s   o f   p a r e n t ,   c h i l d   a n d   s t a f f   s a t i s f a c t i o n   w e r e   r e p o r t e d ,   a l o n g   w i t h   h i g h   l e v e l s   o f   t r e a t m e n t   f i d e l i t y .',\n",
              " 'S t a n d a r d i z e d   e f f e c t   s i z e   e s t i m a t e s   w e r e   p r i m a r i l y   i n   t h e   m e d i u m   a n d   l a r g e   r a n g e s   a n d   f a v o r e d   t h e   t r e a t m e n t   g r o u p .']"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MO7_-Hx5FvS"
      },
      "source": [
        "Alright, now we've preprocessed our wild RCT abstract into all of the same features our model was trained on, we can pass these features to our model and make sequence label predictions!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b7siZa1CQG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5462cc8-151c-45d7-ff05-d3636c5e3b50"
      },
      "source": [
        "# Make predictions on sample abstract features\n",
        "%%time\n",
        "test_abstract_pred_probs = model_5_20k.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.46 s, sys: 48.3 ms, total: 1.51 s\n",
            "Wall time: 1.47 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nxqfCBfCqWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa81c1e5-4609-4851-d338-86c716554e15"
      },
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(8,), dtype=int64, numpy=array([3, 2, 2, 2, 4, 4, 4, 4])>"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSOOV4bp5sZI"
      },
      "source": [
        "Now we've got the predicted sequence label for each line in our sample abstract, let's write some code to visualize each sentence with its predicted label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LduhApa3C1mD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d6369aa-be92-465f-b969-ace6c162b1f4"
      },
      "source": [
        "# Turn prediction class integers into string class names\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['OBJECTIVE',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'METHODS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'RESULTS',\n",
              " 'RESULTS']"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhhDPZSHDCJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a1618a-1f39-483b-a2c7-38f5ea2643fd"
      },
      "source": [
        "# Visualize abstract lines and predicted sequence labels\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OBJECTIVE: This RCT examined the efficacy of a manualized social intervention for children with HFASDs.\n",
            "METHODS: Participants were randomly assigned to treatment or wait-list conditions.\n",
            "METHODS: Treatment included instruction and therapeutic activities targeting social skills, face-emotion recognition, interest expansion, and interpretation of non-literal language.\n",
            "METHODS: A response-cost program was applied to reduce problem behaviors and foster skills acquisition.\n",
            "RESULTS: Significant treatment effects were found for five of seven primary outcome measures (parent ratings and direct child measures).\n",
            "RESULTS: Secondary measures based on staff ratings (treatment group only) corroborated gains reported by parents.\n",
            "RESULTS: High levels of parent, child and staff satisfaction were reported, along with high levels of treatment fidelity.\n",
            "RESULTS: Standardized effect size estimates were primarily in the medium and large ranges and favored the treatment group.\n"
          ]
        }
      ]
    }
  ]
}